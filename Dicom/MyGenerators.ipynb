{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is script is used for program custom generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: scikit-image in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-image) (7.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-image) (3.1.3)\n",
      "Requirement already satisfied: networkx>=2.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-image) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from PyWavelets>=0.4.0->scikit-image) (1.18.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: setuptools in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six>=1.5 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: sklearn in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from sklearn) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\projects\\intepreters\\anaconda\\envs\\tf21\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import math\n",
    "!pip install pydicom\n",
    "!pip install scikit-image\n",
    "!pip install sklearn\n",
    "import pydicom\n",
    "\n",
    "\n",
    "# for preprocessing\n",
    "from skimage.transform import resize\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generators from inheritting Sequence class\n",
    "class DicomGenegeratorAutoTFio(Sequence):\n",
    "    \n",
    "    # default functions needs to be overwriiten\n",
    "    def __init__(self, batch_size, train_or_test, dims=(512, 512),shuffle=True, train_images_root=None, val_images_root=None, n_channels=1, prepro=True):\n",
    "        self.train_images_root = train_images_root\n",
    "        self.val_images_root = val_images_root\n",
    "        self.batch_size = batch_size\n",
    "        self.train_or_test =  train_or_test\n",
    "        self.dims = dims\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.prepro = prepro\n",
    "        \n",
    "        # custom functions inside function---------->\n",
    "        def get_data_paths(root_dir):\n",
    "            all_paths = [] \n",
    "            for each in root_dir:\n",
    "                print(\"root:\", each)\n",
    "                one_root_paths =  sorted(glob(each +'/*.DCM'))\n",
    "                print(\"one_root_paths:\", len(one_root_paths))\n",
    "                print()\n",
    "                all_paths = all_paths+ one_root_paths\n",
    "            return all_paths\n",
    "\n",
    "        if self.train_or_test == \"train\":\n",
    "            self.dcm_paths = get_data_paths(self.train_images_root)\n",
    "#             print(f'Found {len(self.dcm_paths)} training images')\n",
    "        else: \n",
    "            self.dcm_paths =  get_data_paths(self.val_images_root)\n",
    "#             print(f'Found {len(self.dcm_paths)} validation images')\n",
    "\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        num_batches = math.ceil(len(self.dcm_paths) / self.batch_size)\n",
    "#         print(f'Found {len(self.dcm_paths)} {self.train_or_test} images ')\n",
    "        return math.ceil(len(self.dcm_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[idx*self.batch_size: (idx+1)*self.batch_size]\n",
    "        \n",
    "        # Find related DCMs' paths\n",
    "        batch_temp_dcm_paths = [self.dcm_paths[k] for k in indexes]\n",
    "        \n",
    "      \n",
    "        return self._generate_X_X(batch_temp_dcm_paths)\n",
    "    \n",
    "    def preprocessing(self, image):\n",
    "        \"\"\"\n",
    "        --- Rescale Image\n",
    "        --- Rotate Image\n",
    "        --- Resize Image\n",
    "        --- Flip Image\n",
    "        --- PCA etc.\n",
    "        \n",
    "        \"\"\"\n",
    "#         print(\"range before resize:[{},{}]\".format(np.min(image), np.max(image)))\n",
    "        # 1. resize\n",
    "        image = resize(image, self.dims, preserve_range=True) # set preserve_range = True otherwise the range will be changed\n",
    "        # 2. normalization scale image with zero mean and unit std. per image\n",
    "#         print(\"range after resize:[{},{}]\".format(np.min(image), np.max(image)))\n",
    "#         print(\"range before scaling:[{},{}]\".format(np.min(image), np.max(image)))\n",
    "#         print(\"mean before scaling:{}]\".format(np.mean(image)))\n",
    "#         print(\"std before scaling:{}]\".format(np.std(image)))\n",
    "#         print(\"shape before scaling:{}\".format(image.shape))\n",
    "#         image = preprocessing.scale(image.reshape((self.dims[0]*self.dims[1], -1))).reshape(self.dims)\n",
    "#         print(\"mean after scaling:[{}]\".format(np.mean(image)))\n",
    "#         print(\"std after scaling:{}]\".format(np.std(image)))\n",
    "#         print(\"range after scaling:[{},{}]\".format(np.min(image), np.max(image)))\n",
    "#         print(\"shape after scaling:{}\".format(image.shape))\n",
    "        return image\n",
    "    \n",
    "    def _generate_X_X(self, batch_temp_dcm_paths):\n",
    "        \"\"\"\n",
    "        batch_temp_dcm_paths : the batch of paths for reading dcms\n",
    "        return: return the numpy array of dcm raw pix data\n",
    "        \"\"\"\n",
    "        # initialization\n",
    "        X = np.empty((self.batch_size, *self.dims, self.n_channels))\n",
    "#         y = np.empty((self.batch_size), dtype=int)\n",
    "        # Generate data\n",
    "        for i, path in enumerate(batch_temp_dcm_paths):\n",
    "            # Store sample\n",
    "#             print(\"Per DCM path:\",path)\n",
    "            temp = self._load_dcm(path)\n",
    "            # check whether needs to preprocess\n",
    "            if self.prepro ==  True:\n",
    "#                 print(\"prerpocessing.....\")\n",
    "                temp = self.preprocessing(temp)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            X[i,] = np.expand_dims(temp, axis=-1)\n",
    "        \n",
    "        return X, X\n",
    "    \n",
    "    def _generate_Y(self, batch_temp_dcm_paths):\n",
    "        pass\n",
    "    \n",
    "    def _load_dcm(self,dcm_path):\n",
    "#         print(dcm_path)\n",
    "        ds = pydicom.dcmread(dcm_path)\n",
    "        pix = ds.pixel_array\n",
    "#         print(\"Shape info: ---------->\", pix.shape )\n",
    "#         print(\"raw DCM content range [{}, {}]\".format(np.min(pix), np.max(pix)))\n",
    "        return pix\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.dcm_paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 training batches\n",
      "Found 0 validation batches\n",
      "train dataset is ok\n",
      "val dataset is ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # root dirs for dcms\n",
    "    train_images_root = sorted(glob('/media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/*'))\n",
    "    val_images_root = sorted(glob('/media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/*'))\n",
    "    \n",
    "    #hyperparameters\n",
    "    batch_size = 2\n",
    "    \n",
    "    # create generator instances\n",
    "    train_dcm_gen =  DicomGenegeratorAutoTFio(batch_size=batch_size, \n",
    "                                          train_or_test=\"train\", \n",
    "                                          dims =(512, 512),\n",
    "                                          shuffle=False,\n",
    "                                          train_images_root=train_images_root)\n",
    "    val_dcm_gen =  DicomGenegeratorAutoTFio(batch_size=batch_size, \n",
    "                                          train_or_test=\"val\", \n",
    "                                          dims =(512, 512),\n",
    "                                          shuffle=False,\n",
    "                                          val_images_root=val_images_root)\n",
    "    \n",
    "    print(f'Found {train_dcm_gen.__len__()} training batches')\n",
    "    print(f'Found {val_dcm_gen.__len__()} validation batches')\n",
    "    \n",
    "    # check the data in data generator\n",
    "    for idx, data in enumerate(train_dcm_gen):\n",
    "        print(idx)\n",
    "        print(\"train_sample shape:\", data[0].shape) # remember data generator now return (X, X)\n",
    "        print(\"train_target shape:\", data[1].shape)\n",
    "#         print(\"min: {} max:{}\".format(np.min(data), np.max(data)))\n",
    "        \n",
    "    for idx, data in enumerate(val_dcm_gen):\n",
    "        print(idx)\n",
    "        print(\"train_sample shape:\", data[0].shape) # remember data generator now return (X, X)\n",
    "        print(\"train_target shape:\", data[1].shape)\n",
    "#         print(\"min: {} max:{}\".format(np.min(data), np.max(data)))\n",
    "\n",
    "    \n",
    "    print(\"train dataset is ok\")\n",
    "    print(\"val dataset is ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
