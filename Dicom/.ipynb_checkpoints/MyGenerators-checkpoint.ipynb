{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is script is used for program custom generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "  Downloading pydicom-1.4.1-py2.py3-none-any.whl (35.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 35.1 MB 17.1 MB/s eta 0:00:01     |██████████████▏                 | 15.5 MB 17.1 MB/s eta 0:00:02\n",
      "\u001b[?25hInstalling collected packages: pydicom\n",
      "Successfully installed pydicom-1.4.1\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from glob import glob\n",
    "import math\n",
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generators from inheritting Sequence class\n",
    "class DicomGenegeratorAutoTFio(Sequence):\n",
    "    \n",
    "    # default functions needs to be overwriiten\n",
    "    def __init__(self, batch_size, train_or_test, shuffle=True, train_images_root=None, val_images_root=None, n_channels=1):\n",
    "        self.train_images_root = train_images_root\n",
    "        self.val_images_root = val_images_root\n",
    "        self.batch_size = batch_size\n",
    "        self.train_or_test =  train_or_test\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        # custom functions inside function---------->\n",
    "        def get_data_paths(root_dir):\n",
    "            all_paths = [] \n",
    "            for each in root_dir:\n",
    "                print(\"root:\", each)\n",
    "                one_root_paths =  sorted(glob(each +'/*.DCM'))\n",
    "                print(\"one_root_paths:\", len(one_root_paths))\n",
    "                print()\n",
    "                all_paths = all_paths+ one_root_paths\n",
    "            return all_paths\n",
    "\n",
    "        if self.train_or_test == \"train\":\n",
    "            self.dcm_paths = get_data_paths(self.train_images_root)\n",
    "#             print(f'Found {len(self.dcm_paths)} training images')\n",
    "        else: \n",
    "            self.dcm_paths =  get_data_paths(self.val_images_root)\n",
    "#             print(f'Found {len(self.dcm_paths)} validation images')\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        num_batches = math.ceil(len(self.dcm_paths) / self.batch_size)\n",
    "        print(f'Found {len(self.dcm_paths)} {self.train_or_test} images ')\n",
    "        return math.ceil(len(self.dcm_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size: (index+1)*self.batch_size]\n",
    "        \n",
    "        # Find related DCMs' paths\n",
    "        batch_temp_dcm_paths = [self.dcm_paths[k] for k in indexes]\n",
    "        \n",
    "      \n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)\n",
    "    \n",
    "    def _generate_X(self, batch_temp_dcm_paths):\n",
    "        \"\"\"\n",
    "        batch_temp_dcm_paths : the batch of paths for reading dcms\n",
    "        return: return the numpy array of dcm raw pix data\n",
    "        \"\"\"\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        # Generate data\n",
    "        for i, path in enumerate(batch_temp_dcm_paths):\n",
    "            # Store sample\n",
    "            X[i,] = self._load_dcm(path)\n",
    "    \n",
    "    def _generate_Y(self, batch_temp_dcm_paths):\n",
    "        \n",
    "    \n",
    "    def _load_dcm(dcm_path):\n",
    "        ds = pydicom.dcmread(dcm_path)\n",
    "        pix = ds.pixel_array\n",
    "        print(\"Shape info: ---------->\", pix.shape )\n",
    "        print(\"raw DCM content range [{}, {}]\".format(np.min(pix), np.max(pix)))\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "    self.indexes = np.arange(len(self.dcm_paths))\n",
    "    if self.shuffle == True:\n",
    "        np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-006_000\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-008_000\n",
      "one_root_paths: 1182\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-012_000\n",
      "one_root_paths: 665\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-015_001\n",
      "one_root_paths: 1132\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-017_001\n",
      "one_root_paths: 1226\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-019_001\n",
      "one_root_paths: 1176\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-020_002\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-021_001\n",
      "one_root_paths: 1219\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-022_001\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-023_001\n",
      "one_root_paths: 869\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-024_001\n",
      "one_root_paths: 1113\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-027_001\n",
      "one_root_paths: 1232\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-029_001\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-031_001\n",
      "one_root_paths: 1169\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-032_001\n",
      "one_root_paths: 1013\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-033_001\n",
      "one_root_paths: 1076\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-035_001\n",
      "one_root_paths: 1182\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-036_001\n",
      "one_root_paths: 1751\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-037_001\n",
      "one_root_paths: 1213\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-038_001\n",
      "one_root_paths: 1013\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/ZA-039_001\n",
      "one_root_paths: 1344\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/ZA-040_001\n",
      "one_root_paths: 1369\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/ZA-041_001\n",
      "one_root_paths: 17\n",
      "\n",
      "Found 23235 train images \n",
      "Found 11618 training images\n",
      "Found 2730 val images \n",
      "Found 1365 validation images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # root dirs for dcms\n",
    "    train_images_root = sorted(glob('/media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/*'))\n",
    "    val_images_root = sorted(glob('/media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/*'))\n",
    "    \n",
    "    #hyperparameters\n",
    "    batch_size = 2\n",
    "    \n",
    "    # create generator instances\n",
    "    train_dcm_gen =  DicomGenegeratorTFio(batch_size=batch_size, \n",
    "                                          train_or_test=\"train\", \n",
    "                                          shuffle=False,\n",
    "                                          train_images_root=train_images_root)\n",
    "    val_dcm_gen =  DicomGenegeratorTFio(batch_size=batch_size, \n",
    "                                          train_or_test=\"val\", \n",
    "                                          shuffle=False,\n",
    "                                          val_images_root=val_images_root)\n",
    "    \n",
    "    print(f'Found {train_dcm_gen.__len__()} training images')\n",
    "    print(f'Found {val_dcm_gen.__len__()} validation images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
