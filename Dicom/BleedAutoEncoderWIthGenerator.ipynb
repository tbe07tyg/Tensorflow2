{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is used for training auto encoder with custom generator in order to load large dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (1.4.1)\n",
      "\n",
      "--->current working direcotry:\n",
      " /home/ytx/myProjects/TensorflowV2/Dicom\n",
      "--->tensorflow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import math\n",
    "!pip install pydicom\n",
    "import pydicom\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Reshape, Dropout, UpSampling2D\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "# print current working directory and tensorflow version\n",
    "print()\n",
    "print(\"--->current working direcotry:\\n\", os.getcwd())\n",
    "print(\"--->tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #hyperparameters\n",
    "batch_size = 2\n",
    "batch_size =  2\n",
    "image_size = 512\n",
    "EPOCHS = 30\n",
    "img_width = img_height = image_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 512, 512, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 1024)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 64, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 128, 128, 256)     524544    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 256, 256, 128)     131200    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 512, 512, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 512, 512, 64)      32832     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 512, 512, 2)       1154      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 512, 512, 1)       3         \n",
      "=================================================================\n",
      "Total params: 27,898,245\n",
      "Trainable params: 27,898,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "def U_NetV2():\n",
    "    inputs = keras.layers.Input((image_size, image_size, 1))\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(drop5))\n",
    "#     merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv6))\n",
    "#     merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv7))\n",
    "#     merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv8))\n",
    "#     merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(up9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    outputs = Conv2D(1, 1, activation='linear')(conv9)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "model =U_NetV2()\n",
    "model.compile(loss='mse', optimizer='adam',\n",
    "              metrics=['mse'])\n",
    "model.summary()\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=200, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some callbacks\n",
    "# add the image call back\n",
    "import os\n",
    "from datetime import datetime\n",
    "logdir =  os.path.join(\"logs\",\"image\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_img = tf.summary.create_file_writer(logdir + '/img')\n",
    "\n",
    "@tf.function()\n",
    "def draw_input_output(epoch, logs):\n",
    "    output = model.predict(val_dataset)\n",
    "    print(output.shape)\n",
    "    with file_writer_img.as_default():\n",
    "        tf.summary.image(\"test_output\", tf.reshape(output,[-1, image_size , image_size , 1]), step=epoch)\n",
    "#         tf.summary.image(\"test_noisy_input\", tf.reshape(x_test_noisy,[-1, image_size , image_size , 1]), step=epoch)\n",
    "        tf.summary.image(\"test_input\", tf.reshape(val_dataset,[-1, image_size , image_size , 1]), step=epoch)\n",
    "log_mg = keras.callbacks.LambdaCallback(on_epoch_end=draw_input_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: scikit-image in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (0.16.2)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-image) (7.0.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-image) (2.6.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-image) (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from PyWavelets>=0.4.0->scikit-image) (1.18.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (45.1.0.post20200127)\n",
      "Requirement already satisfied: sklearn in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ytx/anaconda3/envs/TF21Wio/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "# import cusstom generator class\n",
    "from MyGenerators import DicomGenegeratorAutoTFio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-006_000\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-008_000\n",
      "one_root_paths: 1182\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-012_000\n",
      "one_root_paths: 665\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-015_001\n",
      "one_root_paths: 1132\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-017_001\n",
      "one_root_paths: 1226\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-019_001\n",
      "one_root_paths: 1176\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-020_002\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-021_001\n",
      "one_root_paths: 1219\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-022_001\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-023_001\n",
      "one_root_paths: 869\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-024_001\n",
      "one_root_paths: 1113\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-027_001\n",
      "one_root_paths: 1232\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-029_001\n",
      "one_root_paths: 1251\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-031_001\n",
      "one_root_paths: 1169\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-032_001\n",
      "one_root_paths: 1013\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-033_001\n",
      "one_root_paths: 1076\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-035_001\n",
      "one_root_paths: 1182\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-036_001\n",
      "one_root_paths: 1751\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-037_001\n",
      "one_root_paths: 1213\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/ZA-038_001\n",
      "one_root_paths: 1013\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/ZA-039_001\n",
      "one_root_paths: 1344\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/ZA-040_001\n",
      "one_root_paths: 1369\n",
      "\n",
      "root: /media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/ZA-041_001\n",
      "one_root_paths: 16\n",
      "\n",
      "Found 23235 train images \n",
      "Found 2729 val images \n",
      "Found 11618 training batches\n",
      "Found 1365 validation batches\n",
      "WARNING:tensorflow:From <ipython-input-6-54aa2f67084f>:39: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11618 steps, validate for 1365 steps\n",
      "Epoch 1/30\n",
      "   85/11618 [..............................] - ETA: 47:00 - loss: 19735.7744 - mse: 19735.7734"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-54aa2f67084f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                             verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF21Wio/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "     # root dirs for dcms\n",
    "    train_images_root = sorted(glob('/media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/train/*'))\n",
    "    val_images_root = sorted(glob('/media/ytx/Japan_Deep_Data/dataset/LeiSang/myTry/BleedingDataDCM/val/*'))\n",
    "    \n",
    "   \n",
    "    \n",
    "    # create generator instances\n",
    "    train_dcm_gen =  DicomGenegeratorAutoTFio(batch_size=batch_size, \n",
    "                                          train_or_test=\"train\", \n",
    "                                          dims =(image_size, image_size),\n",
    "                                          shuffle=False,\n",
    "                                          train_images_root=train_images_root)\n",
    "    val_dcm_gen =  DicomGenegeratorAutoTFio(batch_size=batch_size, \n",
    "                                          train_or_test=\"val\", \n",
    "                                          dims =(image_size, image_size),\n",
    "                                          shuffle=False,\n",
    "                                          val_images_root=val_images_root)\n",
    "    \n",
    "    print(f'Found {len(train_dcm_gen.dcm_paths)} {train_dcm_gen.train_or_test} images ')\n",
    "    print(f'Found {len(val_dcm_gen.dcm_paths)} {val_dcm_gen.train_or_test} images ')\n",
    "    print(f'Found {train_dcm_gen.__len__()} training batches')\n",
    "    print(f'Found {val_dcm_gen.__len__()} validation batches')\n",
    "    \n",
    "    # fit model with built generator\n",
    "#     H = model.fit(train_dcm_gen,\n",
    "#                             validation_data=val_dcm_gen, \n",
    "#                             steps_per_epoch=6, \n",
    "#                             validation_steps=4,\n",
    "#                             epochs=EPOCHS, \n",
    "#                             callbacks=[tensorboard_callback],\n",
    "#                             verbose=1)\n",
    "    H = model.fit_generator(train_dcm_gen,\n",
    "                            validation_data=val_dcm_gen, \n",
    "                            steps_per_epoch=train_dcm_gen.__len__(), \n",
    "                            validation_steps=val_dcm_gen.__len__(),\n",
    "                            epochs=EPOCHS, \n",
    "                            callbacks=[tensorboard_callback],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
