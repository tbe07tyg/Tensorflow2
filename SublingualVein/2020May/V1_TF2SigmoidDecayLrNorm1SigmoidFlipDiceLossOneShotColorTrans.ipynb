{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo From Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda\n",
    "print(tf.test.is_gpu_available())\n",
    "# import tensorflow_addons as tfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from glob import glob\n",
    "# !pip install -q tensorflow-io\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow.keras.preprocessing.image as prep\n",
    "\n",
    "\n",
    "from copy import copy\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## dataset paths\n",
    "train_images = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\raw_col_tr_mixed_inputs/*'))\n",
    "train_masks = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\raw_col_tr_mixed_labels/*'))\n",
    "query_images = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\raw_col_tr_queryPatch/*'))\n",
    "\n",
    "test_query_images = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val_query_inputs/*'))\n",
    "test_images = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val/*'))\n",
    "test_masks = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val_selected_masks\\\\raw/*'))\n",
    "\n",
    "# ## dataset paths in labe windows\n",
    "# train_images = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\ColorTransfer\\\\raw_col_tr_mixed_inputs/*'))\n",
    "# train_masks = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\ColorTransfer\\\\raw_col_tr_mixed_labels/*'))\n",
    "# query_images = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\ColorTransfer\\\\raw_col_tr_queryPatch/*'))\n",
    "\n",
    "# test_query_images = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\lab_dataset\\\\val_query_inputs/*'))\n",
    "# test_images = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\lab_dataset\\\\val/*'))\n",
    "# test_masks = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\lab_dataset\\\\val_selected_masks\\\\raw/*'))\n",
    "# input info\n",
    "# raw TIAS INPUT SIZE 1080X1920\n",
    "raw_w = 1080\n",
    "raw_h =  1920\n",
    "# resize_factor =  4\n",
    "# img_w =  raw_w // resize_factor \n",
    "# img_h =  raw_h // resize_factor\n",
    "img_w =  224\n",
    "img_h =  224 # Pretrained Keras model MobileNetV2 only accept the following input dimensions: [96, 128, 160, 192, 224] \n",
    "\n",
    "print(\"desired img w:\", img_w)\n",
    "print(\"desired img h:\", img_h)\n",
    "\n",
    "\n",
    "# parameters for model\n",
    "BATCH_SIZE = 2\n",
    "OUTPUT_CHANNELS = 3\n",
    "print(\"len of query_images:\", len(query_images))\n",
    "\n",
    "print(\"len of test query_images:\", len(test_query_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  pre-processing funcs define\n",
    "# # check the dataset\n",
    "def plot_input_and_mask(img, seg_label):\n",
    "#     palette = copy(plt.cm.gray)\n",
    "#     palette.set_over('r', 1.0)\n",
    "#     print(\"dicom_path:\", dicom_path)\n",
    "    print(\"input_image.shape\", img.numpy().shape)\n",
    "    print(\"seg_label.shape\", seg_label.numpy().shape)\n",
    "\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,20))\n",
    "    \n",
    "    print()\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('input: range:[{}, {}]'.format((np.min(img)), np.max(img)))\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(seg_label)\n",
    "    axes[1].set_title('seg range:[{}, {}] '.format(np.min(seg_label), np.max(seg_label)))\n",
    "    axes[1].axis('off')\n",
    "#     axes[2].hist(seg_label.numpy().reshape((-1)), bins= 20)\n",
    "#     axes[2].set_title('seg range:[{}, {}] '.format(np.min(seg_label), np.max(seg_label)))\n",
    "#     axes[2].axis('off')\n",
    "\n",
    "def decode_img(img_bytes, img_type=\"bmp\"):\n",
    "    # conver compuresed string to a 3D unit8 tensor\n",
    "    if img_type == \"bmp\":\n",
    "        img = tf.io.decode_bmp(img_bytes, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)  # this will nomrlize within (0 , max)\n",
    "#         # std normal \n",
    "#         img = tf.image.per_image_standardization(img)\n",
    "    else:\n",
    "        img =tf.io.decode_png(img_bytes, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [img_h, img_w])  # A 1-D int32 Tensor of 2 elements: new_height, new_width. The new size for the images.\n",
    "    \n",
    "def label_norm(label):\n",
    "    label /=128\n",
    "    return label\n",
    "    \n",
    "    \n",
    "def load_image(image_path, img_type = \"bmp\"):\n",
    "    img_bytes = tf.io.read_file(image_path)\n",
    "    decoded_img = decode_img(img_bytes, img_type)\n",
    "    \n",
    "    \n",
    "    return decoded_img\n",
    "\n",
    "@tf.function\n",
    "def train_process_func(image_path, mask_path):\n",
    "    # load input\n",
    "    inputs =  load_image(image_path, \"bmp\")\n",
    "    print(\"inputs shape:\", inputs.shape)\n",
    "    # load mask \n",
    "    masks = load_image(mask_path, \"png\")\n",
    "    masks =  label_norm(masks)\n",
    "    print(\"masks shape:\", masks.shape)\n",
    "    \n",
    "#     preprocessing\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        inputs = tf.image.flip_left_right(inputs)\n",
    "        masks = tf.image.flip_left_right(masks)\n",
    "        # need to swap green and red channel\n",
    "        r, g, b =  tf.split(masks, 3, axis=-1)\n",
    "\n",
    "        masks =  tf.concat([g, r, b], axis=-1)\n",
    "        \n",
    "    return inputs, masks\n",
    "\n",
    "@tf.function\n",
    "def test_process_func(image_path, mask_path):\n",
    "    # load input\n",
    "    inputs =  load_image(image_path, \"bmp\")\n",
    "    print(\"inputs shape:\", inputs.shape)\n",
    "    # load mask \n",
    "    masks = load_image(mask_path, \"png\")\n",
    "    masks =  label_norm(masks)\n",
    "    print(\"masks shape:\", masks.shape)\n",
    "    return inputs, masks\n",
    "\n",
    "@tf.function\n",
    "def train_query_process_func(image_path):\n",
    "    # load input\n",
    "    inputs =  load_image(image_path, \"bmp\")\n",
    "    print(\"inputs shape:\", inputs.shape) \n",
    "    return inputs\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_query_process_func(image_path):\n",
    "    # load input\n",
    "    inputs =  load_image(image_path, \"bmp\")\n",
    "    print(\"inputs shape:\", inputs.shape) \n",
    "    return inputs\n",
    "\n",
    "# genrate dataset from dataset paths\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_masks))       \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_masks))  \n",
    "\n",
    "query_dataset = tf.data.Dataset.from_tensor_slices(query_images)  \n",
    "test_query_dataset = tf.data.Dataset.from_tensor_slices(test_query_images)  \n",
    "# check the train_dataset from the paths\n",
    "print(\"\")\n",
    "for data in train_dataset.take(1):\n",
    "    print(data[0])\n",
    "    print(data[1])\n",
    "\n",
    "train_dataset = train_dataset.shuffle(300)\n",
    "query_dataset = query_dataset.shuffle(300)\n",
    "\n",
    "# train_dataset = train_dataset.map(map_func=train_process_func,\n",
    "#                                   num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE).repeat()    #\n",
    "train_dataset = train_dataset.map(map_func=train_process_func,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)  # if use for lop directly on the dataset no repeat()\n",
    "query_dataset =  query_dataset.map(map_func=train_query_process_func,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE) \n",
    "test_query_dataset =  test_query_dataset.map(map_func=test_query_process_func,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE) \n",
    "\n",
    "final_train_dataset =  tf.data.Dataset.zip((train_dataset, query_dataset))\n",
    "\n",
    "print(\"final_train_dataset.element_spec:\", final_train_dataset.element_spec)\n",
    "\n",
    "\n",
    "test_dataset = test_dataset.map(map_func=test_process_func,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)   \n",
    "final_test_dataset =  tf.data.Dataset.zip((test_dataset, test_query_dataset))\n",
    "# check the train image\n",
    "for inputs, masks in train_dataset.take(1):\n",
    "    plot_input_and_mask(inputs[0], masks[0])\n",
    "    fig2, axes2 = plt.subplots(1,1, figsize=(8,8))\n",
    "    axes2.hist( masks[0].numpy().reshape((-1)), bins= 20)\n",
    "    axes2.set_title('seg range:[{}, {}] '.format(np.min( masks[0]), np.max( masks[0])))\n",
    "    \n",
    "for query_img in query_dataset.take(1):\n",
    "    fig3, axes3 = plt.subplots(1,1, figsize=(8,8))\n",
    "    axes3.imshow( query_img[0])\n",
    "    axes3.set_title('query input: range:[{}, {}]'.format((np.min(query_img)), np.max(query_img)))\n",
    "    \n",
    "for final_element in final_train_dataset.take(1):\n",
    "    tr_input =  final_element[0][0]\n",
    "    tr_label =  final_element[0][1]\n",
    "    tr_query =  final_element[1]\n",
    "    fig4, axes4 = plt.subplots(1,3, figsize=(12,12))\n",
    "    print(\"tr_input.shape:\", tr_input.shape)\n",
    "    axes4[0].imshow(tr_input[0])\n",
    "    axes4[0].set_title('input: range:[{}, {}]'.format((np.min(tr_input)), np.max(tr_input)))\n",
    "    axes4[0].axis('off')\n",
    "    axes4[1].imshow(tr_label[0])\n",
    "    axes4[1].set_title('seg range:[{}, {}] '.format(np.min(tr_label), np.max(tr_label)))\n",
    "    axes4[1].axis('off')\n",
    "    axes4[2].imshow(tr_query[0])\n",
    "    axes4[2].set_title('seg range:[{}, {}] '.format(np.min(tr_query), np.max(tr_query)))\n",
    "    axes4[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "for final_element in final_test_dataset.take(1):\n",
    "    tr_input =  final_element[0][0]\n",
    "    tr_label =  final_element[0][1]\n",
    "    tr_query =  final_element[1]\n",
    "    fig4, axes4 = plt.subplots(1,3, figsize=(12,12))\n",
    "    print(\"tr_input.shape:\", tr_input.shape)\n",
    "    axes4[0].imshow(tr_input[0])\n",
    "    axes4[0].set_title('input: range:[{}, {}]'.format((np.min(tr_input)), np.max(tr_input)))\n",
    "    axes4[0].axis('off')\n",
    "    axes4[1].imshow(tr_label[0])\n",
    "    axes4[1].set_title('seg range:[{}, {}] '.format(np.min(tr_label), np.max(tr_label)))\n",
    "    axes4[1].axis('off')\n",
    "    axes4[2].imshow(tr_query[0])\n",
    "    axes4[2].set_title('seg range:[{}, {}] '.format(np.min(tr_query), np.max(tr_query)))\n",
    "    axes4[2].axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[img_h, img_w, 3], include_top=False)\n",
    "tf.keras.utils.plot_model(base_model, to_file=\"base_MobileNetV2.png\", show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the activations of these layers. The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process.\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "print('layers:', layers)\n",
    "\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "down_stack.trainable = True\n",
    "tf.keras.utils.plot_model(down_stack, to_file=\"down_stack.png\", show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples.\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "          tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "up_stack = [\n",
    "    upsample(512, 3),  # 4x4 -> 8x8\n",
    "    upsample(256, 3),  # 8x8 -> 16x16\n",
    "    upsample(128, 3),  # 16x16 -> 32x32\n",
    "    upsample(64, 3),   # 32x32 -> 64x64\n",
    "]\n",
    "\n",
    "\n",
    "# def gram_matrix(features, normalize=True):\n",
    "#     \"\"\" Compute the Gram matrix from features. Inputs: - features: Tensor of shape (1, H, W, C) giving features for a single image. - normalize: optional, whether to normalize the Gram matrix If True, divide the Gram matrix by the number of neurons (H * W * C) Returns: - gram: Tensor of shape (C, C) giving the (optionally normalized) Gram matrices for the input image. \"\"\"\n",
    "#     shape = tf.shape(features)\n",
    "#     features_reshaped = tf.reshape(features, (shape[1]*shape[2], shape[3]))\n",
    "#     gram = tf.matmul(tf.transpose(features_reshaped), features_reshaped)\n",
    "#     if normalize:\n",
    "#         gram /= tf.cast((shape[3] * shape[1] * shape[2]), tf.float32)\n",
    "#     return gram\n",
    "\n",
    "# def style_loss(feats, q_extracted_style_layers, i_extracted_style_layers):\n",
    "#     \"\"\" Computes the style loss at a set of layers. Inputs: - feats: list of the features at every layer of the current image, as produced by the extract_features function. - style_layers: List of layer indices into feats giving the layers to include in the style loss. - style_targets: List of the same length as style_layers, where style_targets[i] is a Tensor giving the Gram matrix the source style image computed at layer style_layers[i]. - style_weights: List of the same length as style_layers, where style_weights[i] is a scalar giving the weight for the style loss at layer style_layers[i]. Returns: - style_loss: A Tensor contataining the scalar style loss. \"\"\"\n",
    "#     total_loss = 0.0\n",
    "#     for i in range(len(q_extracted_style_layers)):\n",
    "#         q_layer_features = q_extracted_style_layers[i]\n",
    "#         i_layer_feautres =  i_extracted_style_layers[i]\n",
    "#         A = gram_matrix(feats[style_layers[i]])\n",
    "#         total_loss += style_weights[i]*tf.reduce_sum((G - A)**2)\n",
    "\n",
    "#     return total_loss\n",
    "    \n",
    "\n",
    "def unet_model(output_channels):\n",
    "    # Create the feature extraction model, input both query input and train _input as pair \n",
    "    query_input = tf.keras.layers.Input(shape=[img_h, img_w,3])\n",
    "    train_input = tf.keras.layers.Input(shape=[img_h, img_w,3])\n",
    "      \n",
    "#     inputs = tf.keras.layers.Input(shape=[img_h, img_w, 3])\n",
    "    x_q = query_input\n",
    "    x_i = train_input\n",
    "    # Downsampling through the model, siamese Network share the same weights\n",
    "    skips_query = down_stack(x_q)\n",
    "    print(\"skips_query\", skips_query)\n",
    "    skips_input = down_stack(x_i)\n",
    "    print(\"skips_input\", skips_input)\n",
    "    \n",
    "    \n",
    "#     # style loss\n",
    "#     style_loss = \n",
    "    \n",
    "    \n",
    "    skips_each_connect = []\n",
    "    for i in range(len(skips_query)):\n",
    "        # concat:\n",
    "        concat_skip= tf.concat([skips_query[i], skips_input[i]], axis = -1)\n",
    "        print(\"concat_skip.shape:\", concat_skip.shape)\n",
    "        # 1x1 convolutions summary \n",
    "        concat_skip_1x1 =  tf.keras.layers.Conv2D(\n",
    "              filters=concat_skip.shape[-1]//2, kernel_size=1, strides=(1, 1), activation='relu')(concat_skip)\n",
    "        print(\"concat_skip_1x1.shape\", concat_skip_1x1.shape)\n",
    "        \n",
    "        skips_each_connect.append(concat_skip_1x1)\n",
    "    \n",
    "    print(\"skips_each_connect summary:\", skips_each_connect)\n",
    "    \n",
    "    x = skips_each_connect[-1]\n",
    "    skips_each_connect = reversed(skips_each_connect[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips_each_connect):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "        output_channels, 3, strides=2,\n",
    "        padding='same')  #64x64 -> 128x128\n",
    "\n",
    "    x = last(x)\n",
    "    \n",
    "    x =  tf.sigmoid(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[query_input, train_input], outputs=x)\n",
    "One_shot_MobileNetV2UNet = unet_model(OUTPUT_CHANNELS)\n",
    "tf.keras.utils.plot_model(One_shot_MobileNetV2UNet, to_file=\"One_shot_MobileNetV2UNet.png\", show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_name\n",
    "project_name = \"DemoSegTF2SigmoidDecayLrNorm1SigmoidFlipOneShotV1_FT_True_ColorTr/\"\n",
    "if not os.path.exists(project_name):\n",
    "    os.makedirs(project_name)\n",
    "# tb_log_name \n",
    "log_dir=project_name + \"AE_logs/\"\n",
    "\n",
    "# image_save name\n",
    "train_save_figure_path = project_name + \"AE_saves/train\"\n",
    "test_save_figure_path = project_name + \"AE_saves/test\"\n",
    "\n",
    "# training_checkpoint name\n",
    "checkpoint_dir = project_name + \"training_checkpoints\"\n",
    "\n",
    "# -------------------------------------------------------------------------->\n",
    "\n",
    "## get current working directory\n",
    "cwd = os.getcwd()\n",
    "print(\"current working directory:\", cwd)\n",
    "train_full_AE_saves =  os.path.join(cwd, train_save_figure_path)\n",
    "test_full_AE_saves =  os.path.join(cwd, test_save_figure_path)\n",
    "print(\"train_full_AE_saves:\", train_full_AE_saves)\n",
    "print(\"test_full_AE_saves:\", test_full_AE_saves)\n",
    "\n",
    "\n",
    "if not os.path.exists(train_full_AE_saves):\n",
    "    os.makedirs(train_full_AE_saves)\n",
    "\n",
    "if not os.path.exists(test_full_AE_saves):\n",
    "    os.makedirs(test_full_AE_saves)\n",
    "    \n",
    "    \n",
    "train_predictions_save_path =os.path.join(train_full_AE_saves, \"Predictions\")\n",
    "# train_clsDistr_save_path =os.path.join(train_full_AE_saves, \"ClassDistruibution\")\n",
    "\n",
    "test_predictions_save_path =os.path.join(test_full_AE_saves, \"Predictions\")\n",
    "\n",
    "# test_confusion_matrix =  os.path.join(test_full_AE_saves, \"Confusion_Matrix\")\n",
    "# test_cm_diags =  os.path.join(test_full_AE_saves, \"Confusion_Matrix_diagnoise_with_Epoch\")\n",
    "\n",
    "# test_batch_losses =  os.path.join(test_full_AE_saves, \"Test_batch_losses\")\n",
    "\n",
    "test_EpochValidation_save_path =os.path.join(test_full_AE_saves, \"EpochValidation\")\n",
    "# test_EpochValidation_save_path_pred =os.path.join(test_EpochValidation_save_path, \"PredictionsOnly\")\n",
    "if not os.path.exists(train_predictions_save_path):\n",
    "    os.makedirs(train_predictions_save_path)\n",
    "# if not os.path.exists(train_clsDistr_save_path):\n",
    "#     os.makedirs(train_clsDistr_save_path)\n",
    "    \n",
    "if not os.path.exists(test_predictions_save_path):\n",
    "    os.makedirs(test_predictions_save_path)\n",
    "if not os.path.exists(test_EpochValidation_save_path):\n",
    "    os.makedirs(test_EpochValidation_save_path)\n",
    "# if not os.path.exists(test_EpochValidation_save_path_pred):\n",
    "#     os.makedirs(test_EpochValidation_save_path_pred)   \n",
    "# if not os.path.exists(test_confusion_matrix):\n",
    "#     os.makedirs(test_confusion_matrix)       \n",
    "# if not os.path.exists(test_cm_diags):\n",
    "#     os.makedirs(test_cm_diags) \n",
    "# if not os.path.exists(test_batch_losses):\n",
    "#     os.makedirs(test_batch_losses)   \n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "# \n",
    "import datetime\n",
    "\n",
    "# for tensorboard writers\n",
    "datetime_rec =  datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"train\")\n",
    "val_summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"val\")\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design new loss for the new model as new_train_step, new_test_step\n",
    "# new_optimizer =  tf.keras.optimizers.Adam(1e-4)\n",
    "# from tf.keras.utils import to_categorical\n",
    "# BCE =  tf.keras.losses.BinaryCrossentropy() \n",
    "# Huber =  tf.keras.losses.Huber(delta=0.1)\n",
    "# SCC = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "@tf.function\n",
    "def dice_coef(y_true, y_pred, smooth=1, input_type=\"RGB\"):\n",
    "    if input_type == \"RGB\":\n",
    "        y_true =  tf.image.rgb_to_grayscale(y_true)\n",
    "        y_pred = tf.image.rgb_to_grayscale(y_pred)\n",
    "        \n",
    "    else: pass\n",
    "    y_true =  tf.cast(tf.math.greater(y_true, 0), tf.float32)\n",
    "    y_pred =  tf.cast(tf.math.greater(y_pred, 0.5), tf.float32)\n",
    "    print(\"y_true.shape\", y_true.shape)\n",
    "    print(\"y_pred.shape\",y_pred.shape)\n",
    "    \n",
    "    intersection = tf.math.reduce_sum(y_true * y_pred)\n",
    "    union = tf.math.reduce_sum(y_true) + tf.math.reduce_sum(y_pred)\n",
    "    dice = tf.reduce_mean((2. * intersection + smooth)/(union + smooth))\n",
    "    return dice\n",
    "\n",
    "@tf.function\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "  return iou\n",
    "\n",
    "@tf.function\n",
    "def Smooth_l1_loss(labels,predictions):\n",
    "    diff=tf.abs(labels-predictions)\n",
    "    less_than_one=tf.cast(tf.less(diff,1.0),tf.float32)   #Bool to float32\n",
    "    smooth_l1_loss=(less_than_one*0.5*diff**2)+(1.0-less_than_one)*(diff-0.5)#同上图公式\n",
    "    return tf.reduce_mean(smooth_l1_loss)\n",
    "\n",
    "@tf.function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    dice_loss =  1- dice_coef(y_true, y_pred)\n",
    "    return dice_loss\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "# define losses\n",
    "def new_compute_loss(pred, seg_label):\n",
    "    \n",
    "#     #seg  cross_entropy,  use reduce mean not sum, otherwise loss will be very big\n",
    "#     cls_BCE_loss1 = BCE(y_true=cls_tars[0], y_pred=preds[0]) \n",
    "#     cls_BCE_loss2 = BCE(y_true=cls_tars[1], y_pred=preds[1]) \n",
    "    L1_smooth_loss = Smooth_l1_loss(seg_label, pred) \n",
    "    Dice_loss = dice_loss(seg_label, pred)\n",
    "    total_loss = L1_smooth_loss + Dice_loss\n",
    "\n",
    "    return total_loss\n",
    "    \n",
    "\n",
    "# @tf.function()\n",
    "def new_train_step(model, optimizer, inputs, seg_target, training):\n",
    "    # change cls labe 0 or 1 into  [1, 0] [0, 1]\n",
    "#     print(cls_target)\n",
    "#     cls_target = mask_to_categorical(cls_target)\n",
    "#     print(\"in trianing step\")\n",
    "    with tf.GradientTape() as tape:  # very interesting\n",
    "        # outputs=[seg_out, class_sigmoid_output] \n",
    "        pred= model(inputs, training=training)\n",
    "        total_loss = new_compute_loss(pred=pred, seg_label=seg_target)\n",
    "        dice = dice_coef(seg_target, pred)\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return total_loss, pred, dice\n",
    "\n",
    "# @tf.function()\n",
    "def new_test_step(model, inputs, seg_target, training):\n",
    "    with tf.GradientTape() as tape:  # if use tf.function. needs to wrap the code with the same variable name otherwise non-first call value error\n",
    "        pred= model(inputs, training=training)\n",
    "        total_loss= new_compute_loss(pred=pred, seg_label=seg_target)\n",
    "        dice = dice_coef(seg_target, pred)\n",
    "    return total_loss, pred, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_predict_images(model, batch_input, batch_seg_target,  batch_idx, epoch, pred=None, save=True, Train_or_not=True, Epoch_val =False ,one_shot =True):\n",
    "    \n",
    "    if pred is None:\n",
    "        \n",
    "#     prediction = model(test_input, training=True)\n",
    "  \n",
    "    \n",
    "        Seg_output = model.predict(batch_input)\n",
    "    else:\n",
    "        Seg_output = pred\n",
    "#     print(\"class_sigmoid_output shape:\", class_sigmoid_output)\n",
    "\n",
    "    if one_shot == True:\n",
    "        single_input =batch_input[0][0].numpy()    \n",
    "        single_query =batch_input[1][0].numpy()\n",
    "    single_seg_pred =  Seg_output[0]\n",
    "  \n",
    "    single_seg_label =batch_seg_target[0].numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2,2, figsize=(15,15))\n",
    "    \n",
    "    eval_dice =  dice_coef(single_seg_label, single_seg_pred)\n",
    "        \n",
    "#     palette = copy(plt.cm.gray)\n",
    "#     palette.set_over('r', 1.0)\n",
    "\n",
    "    print(\"single_input.shape\", single_input.shape)\n",
    "    print(\"single_seg_label.shape\", single_seg_label.shape)\n",
    "    print(\"single_seg_pred.shape\", single_seg_pred.shape)\n",
    "#     num_nonzeros=np.count_nonzero(seg_label)\n",
    "    # reshape label \n",
    "#     target =  tf.reshape(seg_label, norm_input.shape)\n",
    "#     norm_mask =  np.squeeze(target.numpy())\n",
    "#     norm_input = np.squeeze(norm_input.numpy())\n",
    "#     norm_Seg_pred =  np.squeeze(Seg_pred.numpy())\n",
    "#     print(\"norm_mask\", norm_mask.shape)\n",
    "#     print(\"norm_input\", norm_input.shape)\n",
    "#     masked_in = norm_w_input + norm_mask\n",
    "#     print('masked_in range:[{}, {}]'.format((masked_in.min()), masked_in.max()))\n",
    "\n",
    "#     masked = np.ma.masked_where(norm_mask==0, masked_in)  # this is only generated mask\n",
    "#     print('masked range:[{}, {}]'.format(masked.min(), masked.max())) \n",
    "\n",
    "    axes[0, 0].imshow(single_input)\n",
    "    axes[0, 0].set_title('single input range:[{}, {}]'.format(np.min(single_input), np.max(single_input)))\n",
    "    axes[0, 1].imshow(single_query)\n",
    "    axes[0, 1].set_title('single_query range:[{}, {}]'.format(np.min(single_query), np.max(single_query)))\n",
    "    axes[1, 0].imshow(single_seg_label)\n",
    "    axes[1, 0].set_title('label range:[{}, {}]'.format(np.min(single_seg_label), np.max(single_seg_label)))\n",
    "    axes[1, 1].imshow(single_seg_pred)             \n",
    "    axes[1, 1].set_title('pred. range:[{}, {}] \\n dice: {}'.format(np.min(single_seg_pred), np.max(single_seg_pred), eval_dice))\n",
    "#     axes.imshow(masked, palette, colors.Normalize(vmin=0, vmax=1), interpolation='none', alpha=0.4)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save==True :\n",
    "        if Train_or_not:\n",
    "            fig.savefig(train_save_figure_path + \"/Train_image_at_epoch_{:04d}_batch_{}.png\".format(epoch,batch_idx))\n",
    "        else:\n",
    "            if Epoch_val:\n",
    "                fig.savefig(test_EpochValidation_save_path + \"/Test_image_at_epoch_{:04d}_batch_{}_idx.png\".format(epoch,batch_idx))\n",
    "            else:\n",
    "                fig.savefig(test_save_figure_path + \"/Test_image_at_epoch_{:04d}_batch_{}.png\".format(epoch,batch_idx))\n",
    "     \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def test_predict_all_images(model, batch_input, batch_seg_target, epoch, batch):\n",
    "    temp_batch_size = batch_seg_target.shape[0]\n",
    "    print(\"temp_batch_size:\", temp_batch_size)\n",
    "    fig, axes = plt.subplots(batch_seg_target.shape[0], 4, figsize=(30,30))\n",
    "    current_batch_avg_dice = 0\n",
    "    Seg_output = model.predict(batch_input)\n",
    "    for i in range(batch_seg_target.shape[0]):\n",
    "#     print(\"class_sigmoid_output shape:\", class_sigoid_output)\n",
    "        single_seg_pred =  Seg_output[i]\n",
    "        single_input =batch_input[0][i].numpy()\n",
    "        single_query =batch_input[1][i].numpy()\n",
    "        single_seg_label =batch_seg_target[i].numpy()\n",
    "\n",
    "      \n",
    "\n",
    "        eval_dice =  dice_coef(single_seg_label, single_seg_pred)\n",
    "\n",
    "    #     palette = copy(plt.cm.gray)\n",
    "    #     palette.set_over('r', 1.0)\n",
    "        current_batch_avg_dice +=eval_dice\n",
    "        print(\"single_input.shape\", single_input.shape)\n",
    "        print(\"single_seg_label.shape\", single_seg_label.shape)\n",
    "        print(\"single_seg_pred.shape\", single_seg_pred.shape)\n",
    "    #     num_nonzeros=np.count_nonzero(seg_label)\n",
    "        # reshape label \n",
    "    #     target =  tf.reshape(seg_label, norm_input.shape)\n",
    "    #     norm_mask =  np.squeeze(target.numpy())\n",
    "    #     norm_input = np.squeeze(norm_input.numpy())\n",
    "    #     norm_Seg_pred =  np.squeeze(Seg_pred.numpy())\n",
    "    #     print(\"norm_mask\", norm_mask.shape)\n",
    "    #     print(\"norm_input\", norm_input.shape)\n",
    "    #     masked_in = norm_w_input + norm_mask\n",
    "    #     print('masked_in range:[{}, {}]'.format((masked_in.min()), masked_in.max()))\n",
    "\n",
    "    #     masked = np.ma.masked_where(norm_mask==0, masked_in)  # this is only generated mask\n",
    "    #     print('masked range:[{}, {}]'.format(masked.min(), masked.max())) \n",
    "        \n",
    "        if temp_batch_size ==1:\n",
    "            axes[0].imshow(single_input)\n",
    "            axes[0].set_title('input range:[{}, {}]'.format(np.min(single_input), np.max(single_input)))\n",
    "            axes[1].imshow(single_query)\n",
    "            axes[1].set_title('query range:[{}, {}]'.format(np.min(single_query), np.max(single_query)))\n",
    "\n",
    "            axes[2].imshow(single_seg_label)\n",
    "            axes[2].set_title('label range:[{}, {}]'.format(np.min(single_seg_label), np.max(single_seg_label)))\n",
    "            axes[3].imshow(single_seg_pred)             \n",
    "            axes[3].set_title('pred. range:[{}, {}] \\n dice: {}'.format(np.min(single_seg_pred), np.max(single_seg_pred), eval_dice))\n",
    "        else:\n",
    "            axes[i, 0].imshow(single_input)\n",
    "            axes[i, 0].set_title('input range:[{}, {}]'.format(np.min(single_input), np.max(single_input)))\n",
    "            axes[i, 1].imshow(single_query)\n",
    "            axes[i, 1].set_title('query range:[{}, {}]'.format(np.min(single_query), np.max(single_query)))\n",
    "\n",
    "            axes[i, 2].imshow(single_seg_label)\n",
    "            axes[i, 2].set_title('label range:[{}, {}]'.format(np.min(single_seg_label), np.max(single_seg_label)))\n",
    "            axes[i, 3].imshow(single_seg_pred)             \n",
    "            axes[i, 3].set_title('pred. range:[{}, {}] \\n dice: {}'.format(np.min(single_seg_pred), np.max(single_seg_pred), eval_dice))\n",
    "    #     axes.imshow(masked, palette, colors.Normalize(vmin=0, vmax=1), interpolation='none', alpha=0.4)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(test_EpochValidation_save_path + \"/Test_image_at_epoch_{:04d}_batch_{}_idx.png\".format(epoch,i))    \n",
    "        plt.show()\n",
    "    current_batch_avg_dice =  current_batch_avg_dice/batch_seg_target.shape[0]\n",
    "    \n",
    "    return current_batch_avg_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for final_element in final_train_dataset.take(1):\n",
    "    tr_input =  final_element[0][0]\n",
    "    tr_label =  final_element[0][1]\n",
    "    tr_query =  final_element[1]\n",
    "    print(\"tr_input.shape:\", tr_input.shape)\n",
    "    check_predict_images(One_shot_MobileNetV2UNet, [tr_input, tr_query], tr_label, 1, 1, save=False, Train_or_not=True, Epoch_val =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_total_loss_tb(writer, avg_losses, name, epoch):\n",
    "    \"\"\"\n",
    "     avg_losses = [total_loss, seg_loss, cls_loss]\n",
    "    \"\"\"\n",
    "    with writer.as_default():\n",
    "        print(\"writing \"+name +\" logs to tensorboard...\")                                                       \n",
    "        # write scalars to the tensorboard after each train step\n",
    "        tf.summary.scalar(name, avg_losses.result(), step=epoch)\n",
    "        \n",
    "def write_single_scalar_tb(writer, avg_losses, name, epoch):\n",
    "    \"\"\"\n",
    "     avg_losses = [total_loss, seg_loss, cls_loss]\n",
    "    \"\"\"\n",
    "    with writer.as_default():\n",
    "        print(\"writing \"+ name +\" logs to tensorboard...s\")                                                       \n",
    "        # write scalars to the tensorboard after each train step\n",
    "        tf.summary.scalar(name, avg_losses, step=epoch)\n",
    "        \n",
    "def train_display_save_at(model, batch_inputs, batch_labels,   step, epoch, pred, freq_step =200, save=True, Train_or_not=True):\n",
    "    if step % freq_step ==0:\n",
    "        print(\"train image checking----------------------------------------------------------------------------------->\")\n",
    "        check_predict_images(model, batch_inputs, batch_labels,  step, epoch, pred, save=save, Train_or_not=Train_or_not, Epoch_val =False)\n",
    "        \n",
    "def test_at_each_epoch(val_dataset, model, step, epoch, temp_dice, global_count_test, save=True, training=False):\n",
    "    # initialize \n",
    "    epoch_val_flag = True\n",
    "    # initialize for evaluating average metric\n",
    "    test_total_loss_mean = tf.keras.metrics.Mean()\n",
    "    test_total_dice_mean = tf.keras.metrics.Mean()\n",
    "    manual_avg_dice = []\n",
    "    count = 0\n",
    "    for te_final_element in val_dataset:\n",
    "        te_input =  te_final_element[0][0]\n",
    "        te_label =  te_final_element[0][1]\n",
    "        te_query =  te_final_element[1]\n",
    "        \n",
    "        # one train step loss calculation and optimization  model2, inputs, cls_target, training\n",
    "        te_total_loss, te_pred, te_dice = new_test_step(model, [te_input, te_query], te_label, training=False)\n",
    "        test_total_loss_mean(te_total_loss)\n",
    "        test_total_dice_mean(te_dice)\n",
    "#         test_loss_catches.append(te_total_loss)\n",
    "\n",
    "        count+=1\n",
    "        print('[Test]Epoch: {} batch:{} \\n  total_loss set loss: {}, avg dice： {}'.format(epoch, count, test_total_loss_mean.result(), test_total_dice_mean.result()))\n",
    "        \n",
    "        if global_count_test %25 ==0:\n",
    "            display.clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "\n",
    "        current_batch_avg_dice = test_predict_all_images(model, [te_input, te_query], te_label,  epoch, int(global_count_test)%1) \n",
    "#         check_predict_images(model, [te_input, te_query], te_label, step, epoch, pred=te_pred, save=save, Train_or_not=training, Epoch_val=epoch_val_flag)                                               \n",
    "#         display.clear_output(wait=True)\n",
    "        print(\"global_count_test:\", global_count_test)\n",
    "        write_single_scalar_tb(val_summary_writer,  current_batch_avg_dice, \"test_avg_batch_dice\", int(global_count_test)) \n",
    "        \n",
    "        global_count_test.assign_add(1)\n",
    "        \n",
    "        manual_avg_dice.append(current_batch_avg_dice)\n",
    "    epoch_val_flag = False # one epoch finish so set flag back\n",
    "    \n",
    "    \n",
    "#     # write logs to tensorboard:    avg_losses = [total_loss, seg_loss, cls_loss]\n",
    "#     # write test losses to the tensorboard\n",
    "    print(\"writing test logs to tensorboard...\") \n",
    "    write_single_total_loss_tb(val_summary_writer, test_total_loss_mean, \"total_loss_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(val_summary_writer, test_total_dice_mean, \"Avg_dice_per_epoch\", epoch)\n",
    "    write_single_scalar_tb(val_summary_writer,  sum(manual_avg_dice)/len(manual_avg_dice), \"Manul_test_avg_epoch_dice\", epoch) \n",
    "    # check whether needs to save the model\n",
    "    print(\"temp_dice:\", temp_dice.numpy())\n",
    "    if test_total_dice_mean.result() > temp_dice:\n",
    "        save_path =  new_manager.save() # save the checkpoint and return the save path\n",
    "        print(\"Saved checkpoint for epoch {}-  step {}: {}\".format(epoch, step, save_path))\n",
    "        temp_dice.assign(test_total_dice_mean.result())\n",
    "\n",
    "\n",
    "# defin one epoch training for different dataset\n",
    "def train_one_epoch(train_dataset, model, optimizer, step, epoch):\n",
    "    #  initializations at each epoch \n",
    "    train_total_loss_mean = tf.keras.metrics.Mean()\n",
    "    train_total_dice_mean = tf.keras.metrics.Mean()\n",
    "    \n",
    "    \n",
    "    for tr_final_element in train_dataset:\n",
    "        tr_input =  tr_final_element[0][0]\n",
    "        tr_label =  tr_final_element[0][1]\n",
    "        tr_query =  tr_final_element[1]\n",
    " \n",
    "        # one train step loss calculation and optimization\n",
    "        tr_total_loss,tr_pred, tr_dice = new_train_step(model, optimizer, [tr_input, tr_query], tr_label, training=True)\n",
    "        train_total_loss_mean(tr_total_loss)\n",
    "        train_total_dice_mean(tr_dice)\n",
    "        \n",
    "        if optimizer.iterations.numpy() % 10 == 0: \n",
    "            write_single_total_loss_tb(train_summary_writer, train_total_loss_mean, \"train_total_loss_per_batch\", optimizer.iterations.numpy())\n",
    "            write_single_scalar_tb(train_summary_writer,  optimizer._decayed_lr(var_dtype=tf.float32), \"Optimizer Lr\", optimizer.iterations.numpy())\n",
    "            write_single_scalar_tb(train_summary_writer,  train_total_dice_mean.result(), \"Dice\", optimizer.iterations.numpy())\n",
    "        print('Epoch: {} batch:{} \\n Train total_loss set loss: {}, train avg dice: {}'.format(epoch, int(step), train_total_loss_mean.result(), train_total_dice_mean.result()))\n",
    "        \n",
    "        #  model, Tr_dicom_paths, Tr_norm_input, Tr_norm_input_w_image, Tr_norm_seg_label,Tr_cls_label,   step, epoch, freq_step =100, save=True, Train_or_not=True\n",
    "        train_display_save_at(model, [tr_input, tr_query], tr_label,  int(step), epoch, tr_pred, freq_step =20, save=True, Train_or_not=True)\n",
    "\n",
    "        if step % 25 ==0:\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "        step.assign_add(1)\n",
    "        \n",
    "    \n",
    "     # write train epoch average loss to the tensorboard\n",
    "    print(\"writing train logs to tensorboard...\") \n",
    "    write_single_total_loss_tb(train_summary_writer, train_total_loss_mean, \"total_loss_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(train_summary_writer, train_total_dice_mean, \"Avg_dice_per_epoch\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take_new_train_batches =  3035\n",
    "def train_process(train_dataset, val_dataset, model, optimizer, step, start_epoch,global_test_step, global_dice_temp, total_epochs):\n",
    "    # some initial parameters\n",
    "    # test average_loss = for saving the test results\n",
    "#     test_avg_tmp_dice =1\n",
    "#     global_count_test = 1\n",
    "    for epoch in range(int(start_epoch), total_epochs+1):\n",
    "      \n",
    "    \n",
    "        # train one epoch， including loss calculation and optimization\n",
    "        train_one_epoch(train_dataset, model, optimizer, step, epoch)\n",
    "        \n",
    "        # one training epoch ended start to evaluate the performance through entire test dataset\n",
    "        test_at_each_epoch(val_dataset, model, int(step), epoch, temp_dice=global_dice_temp, global_count_test=global_test_step ,save=True, training = False)\n",
    "      \n",
    "      \n",
    "        # when epoch fisnihed add epoch counter and reset the batch step \n",
    "        start_epoch.assign_add(1)     \n",
    "        step.assign(1)\n",
    "        \n",
    "        \n",
    "    # when training finihsed\n",
    "    print(\"training finished\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    init_lr = 5e-4\n",
    "    learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "      initial_learning_rate=init_lr,\n",
    "      decay_steps=10000,\n",
    "      end_learning_rate=0.00005)\n",
    "#     learning_rate_fn = 1e-3\n",
    "    new_optimizer =  tf.keras.optimizers.Adam(learning_rate_fn)\n",
    "    # build_new check point manager\n",
    "    new_ckpt_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    if not os.path.exists(new_ckpt_prefix):\n",
    "        os.makedirs(new_ckpt_prefix)\n",
    "    #  contents of states to be saved as attributes on the checkpoint object\n",
    "    new_ckpt_ob = tf.train.Checkpoint(step= tf.Variable(1),\n",
    "                                      epoch=  tf.Variable(1),\n",
    "                                      global_test_step =  tf.Variable(1),\n",
    "                                      global_dice_temp =  tf.Variable(0.0),\n",
    "                                        optimizer=new_optimizer,\n",
    "                                         model =  One_shot_MobileNetV2UNet\n",
    "                                     )\n",
    "    # define checkpoint manager\n",
    "    new_manager =  tf.train.CheckpointManager(new_ckpt_ob, new_ckpt_prefix, max_to_keep=1)\n",
    "\n",
    "    # check the whether there is a checkpoint in the checkpoint folder, if it is restore from it\n",
    "    if new_manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(new_manager.latest_checkpoint))\n",
    "        new_ckpt_ob.restore(new_manager.latest_checkpoint)\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    # reset checkcpoint.step for each epoch\n",
    "    step =  new_ckpt_ob.step\n",
    "    ckpt_epoch =  new_ckpt_ob.epoch  \n",
    "    optimizer = new_ckpt_ob.optimizer\n",
    "    model = new_ckpt_ob.model\n",
    "    epochs = 500\n",
    "    global_test_step = new_ckpt_ob.global_test_step\n",
    "    global_dice_temp = new_ckpt_ob.global_dice_temp\n",
    "    # start train_process\n",
    "    train_process(final_train_dataset, final_test_dataset, model, optimizer, step, ckpt_epoch, global_test_step, global_dice_temp, total_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
