{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo From Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda\n",
    "print(tf.test.is_gpu_available())\n",
    "# import tensorflow_addons as tfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from glob import glob\n",
    "# !pip install -q tensorflow-io\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow.keras.preprocessing.image as prep\n",
    "\n",
    "\n",
    "from copy import copy\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## dataset paths\n",
    "train_images = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\inputs/*'))\n",
    "train_left_masks = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\train_left_right_binary_label\\\\left/*'))\n",
    "train_right_masks = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\train_left_right_binary_label\\\\right/*'))\n",
    "\n",
    "test_images = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val/*'))\n",
    "test_left_masks = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val_left_right_binary_label\\\\left/*'))\n",
    "test_right_masks = sorted(glob('E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val_left_right_binary_label\\\\right/*'))\n",
    "\n",
    "# for csv label reading \n",
    "train_csv_centroids_left = \"E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\train_left_right_binary_label\\\\left_with_mass_centroid\\\\train_left.csv\"\n",
    "train_csv_centroids_right =  \"E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\train_left_right_binary_label\\\\right_with_mass_centroid\\\\train_right.csv\"\n",
    "\n",
    "test_csv_centroids_left = \"E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val_left_right_binary_label\\\\left_with_mass_centroid\\\\val_left.csv\"\n",
    "test_csv_centroids_right =  \"E:\\\\dataset\\\\SublingualVein\\\\TIASRGB2020\\\\val_left_right_binary_label\\\\right_with_mass_centroid\\\\val_right.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# train_images = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\inputs/*'))\n",
    "# train_left_masks = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\train_left_right_binary_label\\\\left/*'))\n",
    "# train_right_masks = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\train_left_right_binary_label\\\\right/*'))\n",
    "\n",
    "# test_images = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\lab_dataset\\\\val/*'))\n",
    "# test_left_masks = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\val_left_right_binary_label\\\\left/*'))\n",
    "# test_right_masks = sorted(glob('F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\val_left_right_binary_label\\\\right/*'))\n",
    "# # for csv label reading \n",
    "# train_csv_centroids_left = \"F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\centroidsOnly\\\\train_left.csv\"\n",
    "# train_csv_centroids_right =  \"F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\centroidsOnly\\\\train_right.csv\"\n",
    "\n",
    "# test_csv_centroids_left = \"F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\centroidsOnly\\\\val_left.csv\"\n",
    "# test_csv_centroids_right =  \"F:\\\\dataset\\\\TIASRGB2020\\\\left_right_new\\\\centroidsOnly\\\\val_right.csv\"\n",
    "\n",
    "# input info\n",
    "# raw TIAS INPUT SIZE 1080X1920\n",
    "raw_w = 1080\n",
    "raw_h =  1920\n",
    "# resize_factor =  4\n",
    "# img_w =  raw_w // resize_factor \n",
    "# img_h =  raw_h // resize_factor\n",
    "img_w =  224\n",
    "img_h =  224 # Pretrained Keras model MobileNetV2 only accept the following input dimensions: [96, 128, 160, 192, 224] \n",
    "\n",
    "print(\"desired img w:\", img_w)\n",
    "print(\"desired img h:\", img_h)\n",
    "\n",
    "# threshold for clculate distances map\n",
    "th = 0.01\n",
    "\n",
    "# parameters for model\n",
    "BATCH_SIZE = 4\n",
    "OUTPUT_CHANNELS = 2\n",
    "CSV_COLUMNS = [\"fileNames\", \"Cy\", \"Cx\"]\n",
    "print(\"len of train_images:\", len(train_images))\n",
    "\n",
    "print(\"len of test_images:\", len(test_images))\n",
    "print(\"csv columns:\", CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  pre-processing funcs define\n",
    "# # check the dataset\n",
    "def plot_input_and_mask(img, concat_maskss, image_path, left_Center,Right_Center):\n",
    "#     palette = copy(plt.cm.gray)\n",
    "#     palette.set_over('r', 1.0)\n",
    "#     print(\"dicom_path:\", dicom_path)\n",
    "    print(\"image_path:\", image_path)\n",
    "    print(\"input_image.shape\", img.numpy().shape)\n",
    "    print(\"seg_labels.shape\", concat_maskss.numpy().shape)\n",
    "\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    \n",
    "    print()\n",
    "    axes[0,0].imshow(img)\n",
    "    axes[0,0].set_title('input: range:[{}, {}]\\n path:{}'.format((np.min(img)), np.max(img), image_path))\n",
    "    axes[0,0].axis('off')\n",
    "    \n",
    "    # change concat mask with different colors for the different channe， let the channel0 mask to R CHANNEL; CHANNEL 1 MASK TO BE G CHENNEL;\n",
    "    # NEED TO CONCAT ONE MORE ZEORS CHANNEL WITH THE SAME SHAPE AS EACH MASK CHANNEL\n",
    "    blue_channel = np.zeros((concat_maskss.shape[0], concat_maskss.shape[1],1))\n",
    "    print(\"blue channel.shape:\", blue_channel.shape)\n",
    "    rgb_masks = np.concatenate((concat_maskss,blue_channel), axis=-1)\n",
    "    axes[0, 1].set_title('RGB label range:[{}, {}] '.format(np.min(rgb_masks), np.max(rgb_masks)))\n",
    "    axes[0,1].imshow(rgb_masks)\n",
    "    \n",
    "    axes[1, 0].imshow(concat_maskss[:,:,0])\n",
    "    print(\"left_Center:\", left_Center)\n",
    "    print(\"left_Center[0]:\", left_Center[0]*224)\n",
    "    print(\"left_Center[1]:\", left_Center[1]*224)\n",
    "    axes[1, 0].scatter(left_Center[0].numpy()*224, left_Center[1].numpy()*224, s=160, c='C0', marker='+')\n",
    "    axes[1, 0].set_title('left label range:[{}, {}] '.format(np.min(concat_maskss[:,:,0]), np.max(concat_maskss[:,:,0])))\n",
    "    axes[1, 0].axis('off')\n",
    "    axes[1, 1].imshow(concat_maskss[:,:,1])\n",
    "    axes[1, 1].scatter(Right_Center[0].numpy()*224, Right_Center[1].numpy()*224, s=160, c='C0', marker='+')\n",
    "    axes[1, 1].set_title('right label range:[{}, {}] '.format(np.min(concat_maskss[:,:,1]), np.max(concat_maskss[:,:,1])))\n",
    "    print(\"finishe\")\n",
    "#     axes[1, 1].axis('off')\n",
    "\n",
    "def decode_img(img_bytes, img_type=\"bmp\"):\n",
    "    # conver compuresed string to a 3D unit8 tensor\n",
    "    if img_type == \"bmp\":\n",
    "        img = tf.io.decode_bmp(img_bytes, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)  # this will nomrlize within (0 , max)\n",
    "    else:\n",
    "        img =tf.io.decode_png(img_bytes, channels=1)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [img_h, img_w])  # A 1-D int32 Tensor of 2 elements: new_height, new_width. The new size for the images.\n",
    "    \n",
    "def label_norm(label):\n",
    "    label= label/255.0\n",
    "#     print(\"label range: [{}, {}] \".format(np.min(label.numpy()), np.max(label.numpy())))\n",
    "    return label\n",
    " \n",
    "def decode_csv_records(line, mode=\"ALL\"):\n",
    "    FIELD_DEFAULTS = [[\"0.0\"], [0.0], [0.0]]\n",
    "    Columns =  ['fileNames',  'Cy', 'Cx']\n",
    "    # Decode the line into its fields\n",
    "    fields = tf.io.decode_csv(line, FIELD_DEFAULTS)\n",
    "    \n",
    "    print(\"csv fileds:\",  fields)\n",
    "    print(\"csv fileds[0]:\",  fields[0])\n",
    "    # Pack the result into a dictionary\n",
    "    features = dict(zip(Columns,fields))\n",
    "     # Separate the label from the features\n",
    "    C_y = features.pop('Cy')\n",
    "    C_x = features.pop('Cx')\n",
    "    \n",
    "    if mode == \"ALL\":\n",
    "        return fields[0],  fields[1],  fields[2]\n",
    "    else:\n",
    "        return (C_x, C_y)\n",
    "\n",
    "def load_image(image_path, img_type = \"bmp\"):\n",
    "    img_bytes = tf.io.read_file(image_path)\n",
    "    decoded_img = decode_img(img_bytes, img_type)\n",
    "    return decoded_img\n",
    "\n",
    "@tf.function\n",
    "def train_process_func(image_path, left_mask_path, right_mask_path, left_line, right_line):\n",
    "    # load input\n",
    "    inputs =  load_image(image_path, \"bmp\")\n",
    "    print(\"inputs shape:\", inputs.shape)\n",
    "    # load mask \n",
    "    left_masks = load_image(left_mask_path, \"png\")\n",
    "    right_masks = load_image(right_mask_path, \"png\")\n",
    "    left_masks =  label_norm(left_masks)\n",
    "    right_masks =  label_norm(right_masks)\n",
    "    print(\"left_masks shape:\", left_masks.shape)\n",
    "    print(\"right_masks shape:\", right_masks.shape)\n",
    "    \n",
    "    l_C = decode_csv_records(left_line) # l_C: filename, Cy, Cx\n",
    "    r_C = decode_csv_records(right_line)\n",
    "    \n",
    "    L_Cy = tf.expand_dims(l_C[1], -1) # make sclaer shape from ()  to [1]\n",
    "    L_Cx = tf.expand_dims(l_C[2], -1) # make sclaer shape from ()  to [1]\n",
    "    print(\"L_Cx shape:\", L_Cx.shape)\n",
    "    \n",
    "    R_Cy = tf.expand_dims(r_C[1], -1)\n",
    "    R_Cx = tf.expand_dims(r_C[2], -1)\n",
    " \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        inputs = tf.image.flip_left_right(inputs)\n",
    "        left_masks = tf.image.flip_left_right(left_masks)\n",
    "        right_masks = tf.image.flip_left_right(right_masks)\n",
    "        concat_masks = tf.concat([right_masks, left_masks], axis=-1)\n",
    "        \n",
    "        L_Cx =  1-L_Cx\n",
    "        R_Cx =  1-R_Cx\n",
    "        \n",
    "        left_Center = tf.concat([R_Cx, R_Cy], axis=-1)\n",
    "        right_Center = tf.concat([L_Cx, L_Cy], axis=-1)\n",
    "        # need to swap green and red channel\n",
    "#         r, g, b =  tf.split(masks, 3, axis=-1)\n",
    "    else:\n",
    "        concat_masks = tf.concat([left_masks, right_masks], axis=-1) # concat last dimension so the mask shape [w, h, 2]; left:0 ; right :1\n",
    "        left_Center = tf.concat([L_Cx, L_Cy], axis=-1)\n",
    "        right_Center = tf.concat([R_Cx, R_Cy], axis=-1)  #   [2]  x:0, y:1\n",
    "    print(\"concat_masks shape:\", concat_masks.shape)\n",
    "#         masks =  tf.concat([g, r, b], axis=-1)\n",
    "        \n",
    "    return inputs, concat_masks, image_path, left_Center, right_Center  # centers with formmat (x, y)\n",
    "\n",
    "@tf.function\n",
    "def test_process_func(image_path, left_mask_path, right_mask_path, left_line, right_line):\n",
    "    # load input\n",
    "    inputs =  load_image(image_path, \"bmp\")\n",
    "    print(\"inputs shape:\", inputs.shape)\n",
    "      # load mask \n",
    "    left_masks = load_image(left_mask_path, \"png\")\n",
    "    right_masks = load_image(right_mask_path, \"png\")\n",
    "    left_masks =  label_norm(left_masks)\n",
    "    right_masks =  label_norm(right_masks)\n",
    "    print(\"left_masks shape:\", left_masks.shape)\n",
    "    print(\"right_masks shape:\", right_masks.shape)\n",
    "    l_C = decode_csv_records(left_line) # l_C: filename, Cy, Cx\n",
    "    r_C = decode_csv_records(right_line)\n",
    "    \n",
    "    L_Cy = tf.expand_dims(l_C[1], -1) # make sclaer shape from ()  to [1]\n",
    "    L_Cx = tf.expand_dims(l_C[2], -1) # make sclaer shape from ()  to [1]\n",
    "    print(\"L_Cx shape:\", L_Cx.shape)\n",
    "    \n",
    "    R_Cy = tf.expand_dims(r_C[1], -1)\n",
    "    R_Cx = tf.expand_dims(r_C[2], -1)\n",
    "    left_Center = tf.concat([L_Cx, L_Cy], axis=-1)\n",
    "    right_Center = tf.concat([R_Cx, R_Cy], axis=-1)  \n",
    "    concat_masks = tf.concat([left_masks, right_masks], axis=-1) # concat last dimension so the mask shape [w, h, 2]; left:0 ; right :1\n",
    "    print(\"concat_masks shape:\", concat_masks.shape)\n",
    "#         masks =  tf.concat([g, r, b], axis=-1)\n",
    "    return inputs, concat_masks, image_path, left_Center, right_Center\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# genrate dataset from dataset paths\n",
    "train_dataset_images_paths = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset_left_masks_paths = tf.data.Dataset.from_tensor_slices(train_left_masks)\n",
    "train_dataset_right_masks_paths = tf.data.Dataset.from_tensor_slices(train_right_masks)\n",
    "print(\"train_dataset_images_paths:\", train_dataset_images_paths)\n",
    "\n",
    "train_csv_left_lines = tf.data.TextLineDataset(train_csv_centroids_left).skip(1) # skip the first line of records\n",
    "train_csv_right_lines = tf.data.TextLineDataset(train_csv_centroids_right).skip(1) # skip the first line of records\n",
    "print(\"train_csv_right_lines:\", train_csv_right_lines)\n",
    "train_dataset = tf.data.Dataset.zip((train_dataset_images_paths, train_dataset_left_masks_paths, train_dataset_right_masks_paths, train_csv_left_lines, train_csv_right_lines))     \n",
    "\n",
    "# genrate dataset from dataset paths\n",
    "test_dataset_images_paths = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "test_dataset_left_masks_paths = tf.data.Dataset.from_tensor_slices(test_left_masks)\n",
    "test_dataset_right_masks_paths = tf.data.Dataset.from_tensor_slices(test_right_masks)\n",
    "print(\"test_dataset_images_paths:\", test_dataset_images_paths)\n",
    "\n",
    "test_csv_left_lines = tf.data.TextLineDataset(test_csv_centroids_left).skip(1) # skip the first line of records\n",
    "test_csv_right_lines = tf.data.TextLineDataset(test_csv_centroids_right).skip(1) # skip the first line of records\n",
    "print(\"test_csv_right_lines:\", test_csv_right_lines)\n",
    "test_dataset = tf.data.Dataset.zip((test_dataset_images_paths, test_dataset_left_masks_paths, test_dataset_right_masks_paths, test_csv_left_lines, test_csv_right_lines))     \n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_left_masks, test_right_masks))  \n",
    "\n",
    "\n",
    "# train_dataset = tf.data.Dataset.zip(train_dataset, train_csv_left_lines, train_csv_right_lines)\n",
    "\n",
    "\n",
    "# train_centroids_dataset_left = tf.data.experimental.make_csv_dataset(\n",
    "#       train_csv_centroids_left, # 为了示例更容易展示，手动设置较小的值\n",
    "#       batch_size=1,\n",
    "#       column_names=CSV_COLUMNS,\n",
    "#       shuffle = False\n",
    "#   )\n",
    "# train_centroids_dataset_right = tf.data.experimental.make_csv_dataset(\n",
    "#       train_csv_centroids_right, # 为了示例更容易展示，手动设置较小的值\n",
    "#       batch_size=1,\n",
    "#       column_names=CSV_COLUMNS,\n",
    "#       shuffle = False\n",
    "#   )\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# for data in train_dataset.take(1):\n",
    "#     print(data[0])\n",
    "#     print(data[1])\n",
    "\n",
    "# train_dataset = train_dataset.shuffle(300)\n",
    "\n",
    "# train_dataset = train_dataset.map(map_func=train_process_func,\n",
    "#                                   num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE).repeat()    #\n",
    "train_dataset = train_dataset.map(map_func=train_process_func,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE) # if use for lop directly on the dataset no repeat()\n",
    "\n",
    "test_dataset = test_dataset.map(map_func=test_process_func,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)  \n",
    "\n",
    "# # merge the dataset with cetroids labels\n",
    "# Final_train_dataset = tf.data.Dataset.zip((train_dataset, train_centroids_dataset_left, train_centroids_dataset_right))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(300).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "# # check the train image\n",
    "# for inputs, concat_masks, image_path in train_dataset.take(1):\n",
    "#     print(\"input shpae:\", inputs.shape)\n",
    "#     print(\"concat_masks:\", concat_masks.shape)\n",
    "#     plot_input_and_mask(inputs[0],concat_masks[0] ,image_path[0])\n",
    "# #     fig2, axes2 = plt.subplots(1,1, figsize=(8,8))\n",
    "# #     axes2.hist( masks[0].numpy().reshape((-1)), bins= 20)\n",
    "# #     axes2.set_title('seg range:[{}, {}] '.format(np.min( masks[0]), np.max( masks[0])))\n",
    "    \n",
    "# for inputs, concat_masks, image_path in test_dataset.take(1):\n",
    "#     print(\"input shpae:\", inputs.shape)\n",
    "#     print(\"concat_masks:\", concat_masks.shape)\n",
    "#     plot_input_and_mask(inputs[0],concat_masks[0], image_path[0])\n",
    "\n",
    "# def return_left_right_cententers(left_DICT, RIGHT_DICT):\n",
    "#     left_centers = list(zip( left_DICT[\"Cx\"].numpy().reshape([BATCH_SIZE]).tolist(),left_DICT[\"Cy\"].numpy().reshape([BATCH_SIZE]).tolist()))\n",
    "#     right_centers = list(zip( RIGHT_DICT[\"Cx\"].numpy().reshape([BATCH_SIZE]).tolist(),RIGHT_DICT[\"Cy\"].numpy().reshape([BATCH_SIZE]).tolist()))\n",
    "#     return left_centers, right_centers\n",
    "\n",
    "# for sample in Final_train_dataset.take(2):\n",
    "#     print(\"sample:\", len(sample))\n",
    "#     print(\"len of sample[0]:\",len(sample[0]))\n",
    "# #     print(\"len of sample[0][0]:\",len(sample[0][0]))\n",
    "# #     print(\"len of sample[0][1]:\",len(sample[0][1]))\n",
    "# #     print(\"len of sample[0][2]:\",len(sample[0][2]))\n",
    "    \n",
    "#     print(\"sample[0][0]:\", sample[0][0].shape)  # input image\n",
    "#     print(\"sample[0][1]:\", sample[0][1].shape)  # left and right mask\n",
    "#     print(\"sample[0][2]:\", sample[0][2].shape)  # path\n",
    "    \n",
    "#     print(str(sample[0][2].numpy()))\n",
    "    \n",
    "#     print(\"sample[1]:\", sample[1])  # our  left centroids dictionary\n",
    "    \n",
    "#     print(\"sample[2]:\", sample[2])  # our  right centroids dictionary\n",
    "    \n",
    "# #     print(\"sample[1]['fileNames']:\", sample[1]['fileNames'])  # our  left centroids dictionary\n",
    "# #     print(\"sample[2]['fileNames']:\", sample[2]['fileNames'])  # our  right centroids dictionary\n",
    "#     print(\"sample[1]['Cx'].shape:\",list(sample[1]['Cx'].shape))  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cx'] list:\", sample[1]['Cx'].numpy().reshape([4]).tolist())  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cx']:\",sample[1]['Cx'].numpy())  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cy']:\", list(sample[2]['Cy'].numpy()))  # our  right centroids dictionary\n",
    "#     left_centers, right_centers = return_left_right_cententers(sample[1], sample[2])\n",
    "# #     right_centers =return_left_right_cententers(sample[1])\n",
    "    \n",
    "#     print(\"left_center\", left_centers)\n",
    "#     print(\"right_center\", right_centers)\n",
    "# #     print(str(sample[0][2].numpy()))\n",
    "# #     print(\"concat_masks:\", concat_masks.shape)\n",
    "# #     plot_input_and_mask(inputs[0],concat_masks[0], image_path[0])   \n",
    "    \n",
    "#     plot_input_and_mask(sample[0][0][0], sample[0][1][0], sample[0][2][0], left_centers[0],right_centers[0])\n",
    "for element in train_dataset_images_paths.take(1):\n",
    "    print(element)\n",
    "    \n",
    "for element in train_csv_left_lines.take(1):\n",
    "    print(element)\n",
    "    \n",
    "for sample in train_dataset.take(2):\n",
    "    \n",
    "    print()\n",
    "    print(\"check dataset after check\")\n",
    "    print(\"sample:\", len(sample))\n",
    "    \n",
    "    print(\"sample[0]:\", sample[0].shape)\n",
    "    print(\"sample[1]:\", sample[1].shape)\n",
    "    print(\"sample[2]:\", sample[2])\n",
    "    print(\"sample[3]:\", sample[3])\n",
    "    print(\"sample[3][0]:\", sample[3][0])\n",
    "    print(\"sample[3][0][0]:\", sample[3][0][0])\n",
    "    print(\"sample[4]:\", sample[4])\n",
    "#     print(\"len of sample[0]:\",len(sample[0]))\n",
    "#     print(\"len of sample[0][0]:\",len(sample[0][0]))\n",
    "#     print(\"len of sample[0][1]:\",len(sample[0][1]))\n",
    "#     print(\"len of sample[0][2]:\",len(sample[0][2]))\n",
    "    \n",
    "#     print(\"sample[0][0]:\", sample[0][0].shape)  # input image\n",
    "#     print(\"sample[0][1]:\", sample[0][1].shape)  # left and right mask\n",
    "#     print(\"sample[0][2]:\", sample[0][2].shape)  # path\n",
    "    \n",
    "#     print(str(sample[0][2].numpy()))\n",
    "    \n",
    "#     print(\"sample[1]:\", sample[1])  # our  left centroids dictionary\n",
    "    \n",
    "#     print(\"sample[2]:\", sample[2])  # our  right centroids dictionary\n",
    "    \n",
    "# #     print(\"sample[1]['fileNames']:\", sample[1]['fileNames'])  # our  left centroids dictionary\n",
    "# #     print(\"sample[2]['fileNames']:\", sample[2]['fileNames'])  # our  right centroids dictionary\n",
    "#     print(\"sample[1]['Cx'].shape:\",list(sample[1]['Cx'].shape))  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cx'] list:\", sample[1]['Cx'].numpy().reshape([4]).tolist())  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cx']:\",sample[1]['Cx'].numpy())  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cy']:\", list(sample[2]['Cy'].numpy()))  # our  right centroids dictionary\n",
    "#     left_centers, right_centers = return_left_right_cententers(sample[1], sample[2])\n",
    "# #     right_centers =return_left_right_cententers(sample[1])\n",
    "    \n",
    "#     print(\"left_center\", left_centers)\n",
    "#     print(\"right_center\", right_centers)\n",
    "# #     print(str(sample[0][2].numpy()))\n",
    "# #     print(\"concat_masks:\", concat_masks.shape)\n",
    "# #     plot_input_and_mask(inputs[0],concat_masks[0], image_path[0])   \n",
    "    \n",
    "    plot_input_and_mask(sample[0][0], sample[1][0], sample[2][0], sample[3][0], sample[4][0])\n",
    "\n",
    "for sample in test_dataset.take(1):\n",
    "    \n",
    "    print()\n",
    "    print(\"check dataset after check\")\n",
    "    print(\"sample:\", len(sample))\n",
    "    \n",
    "    print(\"sample[0]:\", sample[0].shape)\n",
    "    print(\"sample[1]:\", sample[1].shape)\n",
    "    print(\"sample[2]:\", sample[2])\n",
    "    print(\"sample[3]:\", sample[3])\n",
    "    print(\"sample[3][0]:\", sample[3][0])\n",
    "    print(\"sample[3][0][0]:\", sample[3][0][0])\n",
    "    print(\"sample[4]:\", sample[4])\n",
    "#     print(\"len of sample[0]:\",len(sample[0]))\n",
    "#     print(\"len of sample[0][0]:\",len(sample[0][0]))\n",
    "#     print(\"len of sample[0][1]:\",len(sample[0][1]))\n",
    "#     print(\"len of sample[0][2]:\",len(sample[0][2]))\n",
    "    \n",
    "#     print(\"sample[0][0]:\", sample[0][0].shape)  # input image\n",
    "#     print(\"sample[0][1]:\", sample[0][1].shape)  # left and right mask\n",
    "#     print(\"sample[0][2]:\", sample[0][2].shape)  # path\n",
    "    \n",
    "#     print(str(sample[0][2].numpy()))\n",
    "    \n",
    "#     print(\"sample[1]:\", sample[1])  # our  left centroids dictionary\n",
    "    \n",
    "#     print(\"sample[2]:\", sample[2])  # our  right centroids dictionary\n",
    "    \n",
    "# #     print(\"sample[1]['fileNames']:\", sample[1]['fileNames'])  # our  left centroids dictionary\n",
    "# #     print(\"sample[2]['fileNames']:\", sample[2]['fileNames'])  # our  right centroids dictionary\n",
    "#     print(\"sample[1]['Cx'].shape:\",list(sample[1]['Cx'].shape))  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cx'] list:\", sample[1]['Cx'].numpy().reshape([4]).tolist())  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cx']:\",sample[1]['Cx'].numpy())  # our  left centroids dictionary\n",
    "#     print(\"sample[1]['Cy']:\", list(sample[2]['Cy'].numpy()))  # our  right centroids dictionary\n",
    "#     left_centers, right_centers = return_left_right_cententers(sample[1], sample[2])\n",
    "# #     right_centers =return_left_right_cententers(sample[1])\n",
    "    \n",
    "#     print(\"left_center\", left_centers)\n",
    "#     print(\"right_center\", right_centers)\n",
    "# #     print(str(sample[0][2].numpy()))\n",
    "# #     print(\"concat_masks:\", concat_masks.shape)\n",
    "# #     plot_input_and_mask(inputs[0],concat_masks[0], image_path[0])   \n",
    "    \n",
    "    plot_input_and_mask(sample[0][0], sample[1][0], sample[2][0], sample[3][0], sample[4][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[img_h, img_w, 3], include_top=False)\n",
    "# tf.keras.utils.plot_model(base_model, to_file=\"base_MobileNetV2.png\", show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the activations of these layers. The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process.\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "print('layers:', layers)\n",
    "\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "down_stack.trainable = True\n",
    "tf.keras.utils.plot_model(down_stack, to_file=\"down_stack.png\", show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples.\n",
    "from tensorflow.keras.layers import Lambda, Dense\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "          tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "up_stack = [\n",
    "    upsample(512, 3),  # 4x4 -> 8x8\n",
    "    upsample(256, 3),  # 8x8 -> 16x16\n",
    "    upsample(128, 3),  # 16x16 -> 32x32\n",
    "    upsample(64, 3),   # 32x32 -> 64x64\n",
    "]\n",
    "\n",
    "\n",
    "# def gram_matrix(features, normalize=True):\n",
    "#     \"\"\" Compute the Gram matrix from features. Inputs: - features: Tensor of shape (1, H, W, C) giving features for a single image. - normalize: optional, whether to normalize the Gram matrix If True, divide the Gram matrix by the number of neurons (H * W * C) Returns: - gram: Tensor of shape (C, C) giving the (optionally normalized) Gram matrices for the input image. \"\"\"\n",
    "#     shape = tf.shape(features)\n",
    "#     features_reshaped = tf.reshape(features, (shape[1]*shape[2], shape[3]))\n",
    "#     gram = tf.matmul(tf.transpose(features_reshaped), features_reshaped)\n",
    "#     if normalize:\n",
    "#         gram /= tf.cast((shape[3] * shape[1] * shape[2]), tf.float32)\n",
    "#     return gram\n",
    "\n",
    "# def style_loss(feats, q_extracted_style_layers, i_extracted_style_layers):\n",
    "#     \"\"\" Computes the style loss at a set of layers. Inputs: - feats: list of the features at every layer of the current image, as produced by the extract_features function. - style_layers: List of layer indices into feats giving the layers to include in the style loss. - style_targets: List of the same length as style_layers, where style_targets[i] is a Tensor giving the Gram matrix the source style image computed at layer style_layers[i]. - style_weights: List of the same length as style_layers, where style_weights[i] is a scalar giving the weight for the style loss at layer style_layers[i]. Returns: - style_loss: A Tensor contataining the scalar style loss. \"\"\"\n",
    "#     total_loss = 0.0\n",
    "#     for i in range(len(q_extracted_style_layers)):\n",
    "#         q_layer_features = q_extracted_style_layers[i]\n",
    "#         i_layer_feautres =  i_extracted_style_layers[i]\n",
    "#         A = gram_matrix(feats[style_layers[i]])\n",
    "#         total_loss += style_weights[i]*tf.reduce_sum((G - A)**2)\n",
    "\n",
    "#     return total_loss\n",
    "\n",
    "# def euclidean_distance(vects):\n",
    "#     x, y = vects\n",
    "#     sum_square =tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "# #     return tf.math.sqrt(K.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "#     return tf.math.sqrt(K.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "#     return tf.math.sqrt(sum_square)\n",
    "\n",
    "# def feature_extraction():\n",
    "#     query_input = tf.keras.layers.Input(shape=[img_h, img_w,3])\n",
    "#     train_input = tf.keras.layers.Input(shape=[img_h, img_w,3])\n",
    "#     skips_query = down_stack(x_q)\n",
    "#     print(\"skips_query\", skips_query)\n",
    "#     skips_input = down_stack(x_i)\n",
    "#     print(\"skips_input\", skips_input)\n",
    "#     return  tf.keras.Model(inputs=[query_input, train_input], skips_input=[skips_input, skips_query]) \n",
    "\n",
    "# feature_extractor = feature_extraction() \n",
    "def unet_model(output_channels):\n",
    "    inputs = tf.keras.layers.Input(shape=[img_h, img_w, 3])\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "        output_channels, 3, strides=2,\n",
    "        padding='same')  #64x64 -> 128x128\n",
    "\n",
    "    x = last(x)\n",
    "    \n",
    "    x =  tf.sigmoid(x)\n",
    "  \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "#     x =  tf.sigmoid(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "One_shot_MobileNetV2UNet = unet_model(OUTPUT_CHANNELS)\n",
    "# tf.keras.utils.plot_model(One_shot_MobileNetV2UNet, to_file=\"One_shot_MobileNetV2UNet.png\", show_shapes=True, dpi=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check feature extractor\n",
    "# tf.keras.utils.plot_model(feature_extractor, to_file=\"feature_extractor.png\", show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check entire model\n",
    "tf.keras.utils.plot_model(One_shot_MobileNetV2UNet, to_file=\"One_shot_MobileNetV2UNet.png\", show_shapes=True, dpi=64)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_name\n",
    "project_name = \"NEW_BASE_UNET_1Input_DiceCircleIoU_TH{}/\".format(th)\n",
    "if not os.path.exists(project_name):\n",
    "    os.makedirs(project_name)\n",
    "# tb_log_name \n",
    "log_dir=project_name + \"AE_logs/\"\n",
    "\n",
    "# image_save name\n",
    "train_save_figure_path = project_name + \"AE_saves/train\"\n",
    "test_save_figure_path = project_name + \"AE_saves/test\"\n",
    "\n",
    "# training_checkpoint name\n",
    "checkpoint_dir = project_name + \"training_checkpoints\"\n",
    "\n",
    "# -------------------------------------------------------------------------->\n",
    "\n",
    "## get current working directory\n",
    "cwd = os.getcwd()\n",
    "print(\"current working directory:\", cwd)\n",
    "train_full_AE_saves =  os.path.join(cwd, train_save_figure_path)\n",
    "test_full_AE_saves =  os.path.join(cwd, test_save_figure_path)\n",
    "print(\"train_full_AE_saves:\", train_full_AE_saves)\n",
    "print(\"test_full_AE_saves:\", test_full_AE_saves)\n",
    "\n",
    "\n",
    "if not os.path.exists(train_full_AE_saves):\n",
    "    os.makedirs(train_full_AE_saves)\n",
    "\n",
    "if not os.path.exists(test_full_AE_saves):\n",
    "    os.makedirs(test_full_AE_saves)\n",
    "    \n",
    "    \n",
    "train_predictions_save_path =os.path.join(train_full_AE_saves, \"Predictions\")\n",
    "# train_clsDistr_save_path =os.path.join(train_full_AE_saves, \"ClassDistruibution\")\n",
    "train_distance_save_path =os.path.join(train_full_AE_saves, \"distance_map\")\n",
    "\n",
    "\n",
    "test_predictions_save_path =os.path.join(test_full_AE_saves, \"Predictions\")\n",
    "\n",
    "# test_confusion_matrix =  os.path.join(test_full_AE_saves, \"Confusion_Matrix\")\n",
    "# test_cm_diags =  os.path.join(test_full_AE_saves, \"Confusion_Matrix_diagnoise_with_Epoch\")\n",
    "\n",
    "# test_batch_losses =  os.path.join(test_full_AE_saves, \"Test_batch_losses\")\n",
    "\n",
    "test_EpochValidation_save_path =os.path.join(test_full_AE_saves, \"EpochValidation\")\n",
    "test_distance_save_path =os.path.join(test_full_AE_saves, \"distance_map\")\n",
    "# test_EpochValidation_save_path_pred =os.path.join(test_EpochValidation_save_path, \"PredictionsOnly\")\n",
    "if not os.path.exists(train_predictions_save_path):\n",
    "    os.makedirs(train_predictions_save_path)\n",
    "# if not os.path.exists(train_clsDistr_save_path):\n",
    "#     os.makedirs(train_clsDistr_save_path)\n",
    "    \n",
    "if not os.path.exists(test_predictions_save_path):\n",
    "    os.makedirs(test_predictions_save_path)\n",
    "if not os.path.exists(test_EpochValidation_save_path):\n",
    "    os.makedirs(test_EpochValidation_save_path)\n",
    "    \n",
    "if not os.path.exists(test_distance_save_path):\n",
    "    os.makedirs(test_distance_save_path)\n",
    "if not os.path.exists(train_distance_save_path):\n",
    "    os.makedirs(train_distance_save_path)\n",
    "# if not os.path.exists(test_EpochValidation_save_path_pred):\n",
    "#     os.makedirs(test_EpochValidation_save_path_pred)   \n",
    "# if not os.path.exists(test_confusion_matrix):\n",
    "#     os.makedirs(test_confusion_matrix)       \n",
    "# if not os.path.exists(test_cm_diags):\n",
    "#     os.makedirs(test_cm_diags) \n",
    "# if not os.path.exists(test_batch_losses):\n",
    "#     os.makedirs(test_batch_losses)   \n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "# \n",
    "import datetime\n",
    "\n",
    "# for tensorboard writers\n",
    "datetime_rec =  datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"train\")\n",
    "val_summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"val\")\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design new loss for the new model as new_train_step, new_test_step\n",
    "# new_optimizer =  tf.keras.optimizers.Adam(1e-4)\n",
    "# from tf.keras.utils import to_categorical\n",
    "# BCE =  tf.keras.losses.BinaryCrossentropy() \n",
    "# Huber =  tf.keras.losses.Huber(delta=0.1)\n",
    "# SCC = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# @tf.function\n",
    "# def dice_coef(y_true, y_pred, smooth=1, input_type=\"RGB\"):\n",
    "# #     if input_type == \"RGB\":\n",
    "# #         y_true =  tf.image.rgb_to_grayscale(y_true)\n",
    "# #         y_pred = tf.image.rgb_to_grayscale(y_pred)\n",
    "        \n",
    "# #     else: pass\n",
    "#     y_true =  tf.cast(tf.math.greater(y_true, 0), tf.float32)\n",
    "#     y_pred =  tf.cast(tf.math.greater(y_pred, 0.5), tf.float32)\n",
    "#     print(\"y_true.shape\", y_true)\n",
    "#     print(\"y_pred.shape\",y_pred)\n",
    "    \n",
    "#     intersection = tf.math.reduce_sum(y_true * y_pred)\n",
    "#     union = tf.math.reduce_sum(y_true) + tf.math.reduce_sum(y_pred)\n",
    "#     dice = tf.reduce_mean((2. * intersection + smooth)/(union + smooth))\n",
    "#     return dice\n",
    "\n",
    "# @tf.function\n",
    "# def iou_coef(y_true, y_pred, smooth=1):\n",
    "#   intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "#   union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "#   iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "#   return iou\n",
    "\n",
    "# @tf.function\n",
    "# def Smooth_l1_loss(labels,predictions):\n",
    "#     diff=tf.abs(labels-predictions)\n",
    "#     less_than_one=tf.cast(tf.less(diff,1.0),tf.float32)   #Bool to float32\n",
    "#     smooth_l1_loss=(less_than_one*0.5*diff**2)+(1.0-less_than_one)*(diff-0.5)#同上图公式\n",
    "#     return tf.reduce_mean(smooth_l1_loss)\n",
    "\n",
    "def calculate_distance2D_list(tensor, center, pred=\"Pred\", save=False, epoch =1,batch=1, idx=1):\n",
    "    \"\"\"\n",
    "    tensor: [H, W]\n",
    "    \"\"\"\n",
    "#     if pred == \"Pred\":\n",
    "#         print(\"Pred\")\n",
    "# #         flatted_img_array = tensor.flatten()\n",
    "#     else:\n",
    "#         print(\"target\")\n",
    "    if 'numpy' in str(type(tensor)):\n",
    "        flatted_img_array = tensor.flatten()\n",
    "    else:\n",
    "        flatted_img_array = tensor.numpy().flatten()\n",
    "#     print(\"tensor shape:\", tensor)\n",
    "   \n",
    "    nonzeros_bool  =  tf.greater(tensor, th)\n",
    "    nonzeros_indices  =  tf.where(nonzeros_bool)  # [num_nonzeros, 2]---> 2 ： rows, columns\n",
    "#     print(\"nonzeros_indices:\", nonzeros_indices)\n",
    "    if nonzeros_indices.numpy().size:\n",
    "#         print(nonzeros_indices.shape)\n",
    "         # calculate \n",
    "        rows_indices = nonzeros_indices[:, 0] /224  # normalized to  [0, 1]\n",
    "        cols_indices = nonzeros_indices[:, 1]/224\n",
    "        nonzeros_indices2 = np.nonzero(tf.reshape(nonzeros_bool, [-1]))\n",
    "#         print(\"nonzeros_indices2:\", nonzeros_indices2[0].shape)\n",
    "    else:\n",
    "         # calculate \n",
    "        allzeros_bool  =  tf.math.equal(nonzeros_bool, False) \n",
    "        allzeros_indices = tf.where(allzeros_bool)\n",
    "        rows_indices = allzeros_indices[:, 0] /224  # normalized to  [0, 1]\n",
    "        cols_indices = allzeros_indices[:, 1] /224\n",
    "#         print(\"allzeros_indices:\", allzeros_indices.shape)\n",
    "        print(\"ALL black tensor!\")\n",
    "        nonzeros_indices2 = range(224*224)\n",
    "#         print(\"nonzeros_indices2:\", len(nonzeros_indices2))\n",
    "   \n",
    "    #center(x, y) = > y: rows; x==> columns\n",
    "    center_row =  center[1]  # normalized \n",
    "    center_col =  center[0]\n",
    "#     print(\"center_row:\", center_row)\n",
    "#     print(\"center_col:\", center_col)\n",
    "#     print(\"rows_indices：\", rows_indices) \n",
    "    # calculate the row distnaces\n",
    "    row_distances =  tf.math.square(tf.cast(rows_indices, tf.float32)- center_row)\n",
    "#     print(\"row_distances:\", row_distances)\n",
    "    col_distances =  tf.math.square(tf.cast(cols_indices, tf.float32)- center_col)\n",
    "    final_distances =  tf.math.sqrt(row_distances+ col_distances)\n",
    "    \n",
    "#     print(\"final_distances:\", final_distances.numpy().shape)\n",
    "    \n",
    "    # generate distance map----->\n",
    "    if save:\n",
    "#         print(\"tensor:\", tensor.shape)\n",
    "        \n",
    "        max_dis= tf.math.reduce_max(final_distances)\n",
    "        min_dis= tf.math.reduce_min(final_distances)\n",
    "       \n",
    "#         print(\"flatted_img_array.shape\", flatted_img_array.shape)\n",
    "    \n",
    "#         print(\"flatted_img_array:\", flatted_img_array.shape)\n",
    "        print(\"final_distances shape:\",final_distances.shape)\n",
    "        flatted_img_array[nonzeros_indices2]=final_distances\n",
    "        img_dis_map = flatted_img_array.reshape((224, 224))\n",
    "#         figure = plt.figure(figsize=(8, 8))\n",
    "#         plt.imshow(img_dis_map,interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#         plt.colorbar() \n",
    "#         plt.savefig(train_save_figure_path + \"/distanceMap{}_at_epoch_{:04d}_batch_{}_idx_{}.png\".format(pred,epoch,batch, idx), dpi=300, transparent=False, bbox_inches='tight') \n",
    "        return img_dis_map, min_dis, max_dis\n",
    "    else:\n",
    "#         pass\n",
    "        return final_distances\n",
    "\n",
    "def calculate_batch_max_distances_list(left_centers, right_centers, tensor, pred=True):\n",
    "    \"\"\"\n",
    "    tensor: shape[batch, h,w, 2]\n",
    "    \"\"\"\n",
    "    # [batch, 1, 1, 2]\n",
    "    batch_max_left_distances = []\n",
    "    batch_max_right_distances = []\n",
    "    for i in range(left_centers.shape[0]):\n",
    "        left_center = left_centers[i]\n",
    "        right_center =right_centers[i]\n",
    "        one_batch_tensor =  tensor[i]\n",
    "#         print(\"one_batch_tensor.shape:\", one_batch_tensor.shape)\n",
    "        \n",
    "        # for left ======>\n",
    "        one_batch_prediction_left = one_batch_tensor[:,:, 0]\n",
    "#         print(\"one_batch_left.shape:\", one_batch_prediction_left.shape)\n",
    "        # calculate distances for left:\n",
    "        left_distances_list = calculate_distance2D_list(one_batch_prediction_left, left_center, pred=pred)\n",
    "        # find max distances of calculated disntaces\n",
    "        single_left_batch_max_dis =  tf.math.reduce_max(left_distances_list)\n",
    "        batch_max_left_distances.append(single_left_batch_max_dis)\n",
    "        \n",
    "        \n",
    "        # for right ====>\n",
    "        one_batch_prediction_right = one_batch_tensor[:,:, 1]\n",
    "#         print(\"one_batch_right.shape:\", one_batch_prediction_right.shape)\n",
    "        # calculate distances for left:\n",
    "        right_distances_list = calculate_distance2D_list(one_batch_prediction_right, right_center, pred=pred)\n",
    "        # find max distances of calculated disntaces\n",
    "        single_right_batch_max_dis =  tf.math.reduce_max(right_distances_list)\n",
    "        batch_max_right_distances.append(single_right_batch_max_dis)\n",
    "    return batch_max_left_distances, batch_max_right_distances\n",
    "\n",
    "\n",
    "def calculate_batch_CircleIoU_loss(predictions, targets, left_centers, right_centers):\n",
    "    pred_batch_max_left_distances, pred_batch_max_right_distances = calculate_batch_max_distances_list(left_centers, right_centers, predictions, pred=\"Pred\")\n",
    "    tar_batch_max_left_distances, tar_batch_max_right_distances = calculate_batch_max_distances_list(left_centers, right_centers, targets, pred= \"Tar\")\n",
    "    C_iou_loss_list = []\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        \n",
    "        nonzeros_check_bool  =  tf.greater(targets, th) # if no pixel is less than th , all black tensor\n",
    "        nonzeros_check_indices  =  tf.where(nonzeros_check_bool) \n",
    "        is_allblack =  tf.equal(tf.size(nonzeros_check_indices), 0)\n",
    "        if is_allblack:\n",
    "            # for left:===/\n",
    "            # find non zeros of predictions\n",
    "            pred_left_slice =  predictions[[:,:, 0]]\n",
    "            nonzeros_left_bool =  tf.greater(targets, th)\n",
    "            \n",
    "            # for right:\n",
    "        # for left\n",
    "        pre_max_left =  pred_batch_max_left_distances[i]\n",
    "        tar_max_left =  tar_batch_max_left_distances[i]\n",
    "        \n",
    "        min_r_left =  tf.math.reduce_min([pre_max_left, tar_max_left])\n",
    "        max_r_left =  tf.math.reduce_max([pre_max_left, tar_max_left])\n",
    "        \n",
    "        C_iou_left =  min_r_left/max_r_left\n",
    "        \n",
    "        C_iou_loss_left =  -tf.math.log(C_iou_left)\n",
    "        \n",
    "         # for right\n",
    "        pre_max_right =  pred_batch_max_right_distances[i]\n",
    "        tar_max_right =  tar_batch_max_right_distances[i]   \n",
    "        min_r_right =  tf.math.reduce_min([pre_max_right, tar_max_right])\n",
    "        max_r_right =  tf.math.reduce_max([pre_max_right, tar_max_right])\n",
    "        \n",
    "        C_iou_right =  min_r_right/max_r_right\n",
    "        C_iou_loss_right =  -tf.math.log(C_iou_right)\n",
    "        # final left_and_right_IoU\n",
    "        C_iou_loss = C_iou_loss_left + C_iou_loss_right\n",
    "        \n",
    "        C_iou_loss_list.append(C_iou_loss)\n",
    "    final_c_iou_loss =  tf.math.reduce_mean(C_iou_loss_list)\n",
    "    return final_c_iou_loss\n",
    "        \n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def dice_loss(y_true, y_pred):\n",
    "#     dice_loss =  1- dice_coef(y_true, y_pred)\n",
    "#     return dice_loss\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "#     print(\"[dice_loss] y_pred=\",y_pred,\"y_true=\",y_true)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "\n",
    "    return 1 - numerator / denominator\n",
    "\n",
    "# @tf.function()\n",
    "# define losses\n",
    "def new_compute_loss(seg_truth, seg_pred, centers_left, centers_right):\n",
    "    Dice_loss = dice_loss(seg_truth, seg_pred)\n",
    "    dice = 1 - Dice_loss\n",
    "    \n",
    "    c_iou_loss = calculate_batch_CircleIoU_loss(seg_pred, seg_truth, centers_left, centers_right)\n",
    "#     Dice_loss = Smooth_l1_loss(seg_truth, seg_pred)\n",
    "    total_loss = Dice_loss + c_iou_loss\n",
    "\n",
    "    return total_loss, dice, Dice_loss, c_iou_loss\n",
    "    \n",
    "\n",
    "# @tf.function()\n",
    "def new_train_step(model, optimizer, inputs, seg_target, centers_left, centers_right, training):\n",
    "    with tf.GradientTape() as tape:  # very interesting\n",
    "\n",
    "        seg_pred = model(inputs, training=training)\n",
    "#         print(Upper_mean_feature_maps.shape)\n",
    "#         print(seg_pred.shape)\n",
    "        total_loss, dice, Dice_loss, c_iou_loss = new_compute_loss(seg_truth =seg_target, \n",
    "                                                                   seg_pred= seg_pred,\n",
    "                                                                   centers_left= centers_left, \n",
    "                                                                   centers_right= centers_right)\n",
    "#         dice = dice_coef(seg_target, seg_pred)\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return total_loss, seg_pred, dice, Dice_loss, c_iou_loss\n",
    "\n",
    "# @tf.function()\n",
    "def new_test_step(model, inputs, seg_target, centers_left, centers_right, training):\n",
    "    with tf.GradientTape() as tape:  # if use tf.function. needs to wrap the code with the same variable name otherwise non-first call value error\n",
    "        seg_pred = model(inputs, training=training)\n",
    "        total_loss, dice, Dice_loss, c_iou_loss = new_compute_loss(seg_truth =seg_target, \n",
    "                                                                   seg_pred= seg_pred,\n",
    "                                                                   centers_left= centers_left, \n",
    "                                                                   centers_right= centers_right)\n",
    "#         dice = dice_coef(seg_target, seg_pred)\n",
    "    return total_loss, seg_pred, dice, Dice_loss, c_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "def check_predictions(model, tr_element, epoch, batch, save =True, train=False):\n",
    "    train_inputs =  tr_element[0]\n",
    "    train_labels =  tr_element[1]\n",
    "    train_paths =  tr_element[2]\n",
    "    l_centers = tr_element[3]\n",
    "    r_centers = tr_element[4]\n",
    "#     l_centers, r_centers = return_left_right_cententers(tr_element[1], tr_element[2])\n",
    "    \n",
    "    seg_predicts = model.predict(train_inputs)\n",
    "    \n",
    "    d_loss = dice_loss(train_labels, seg_predicts)\n",
    "    \n",
    "    c_iou_loss = calculate_batch_CircleIoU_loss(seg_predicts, train_labels, l_centers, r_centers)\n",
    "    print(\"d_loss:\", d_loss)\n",
    "    for i in range(train_inputs.shape[0]):\n",
    "        \n",
    "        print(\"model_outputs shape:\", seg_predicts.shape)\n",
    "    #         print(\"ed_loss:\", ed_loss)\n",
    "    #         print(\"mean_feature_maps shape:\", mean_feature_maps.shape)\n",
    "\n",
    "    #     print(\"class_sigmoid_output shape:\", class_sigmoid_output)\n",
    "\n",
    "\n",
    "        single_input =train_inputs[i].numpy()    \n",
    "        single_target = train_labels[i].numpy()\n",
    "        single_pred = seg_predicts[i]\n",
    "        single_l_center =  l_centers[i].numpy()\n",
    "        single_r_center =  r_centers[i].numpy()\n",
    "        \n",
    "        # check the distance masp: calculate_distance2D_list(tensor, center, pred=True, save=False, epoch =1,batch=1, idx=1)\n",
    "        if save:\n",
    "            img_dis_map_left, tar_left_min_dis, tar_left_max_dis= calculate_distance2D_list(single_target[:,:, 0], single_l_center,pred=\"Target\", save=save, epoch=epoch, batch=batch, idx=i)\n",
    "            img_dis_map_right, tar_right_min_dis, tar_right_max_dis = calculate_distance2D_list(single_target[:,:, 1], single_r_center,pred=\"Target\", save=save, epoch=epoch, batch=batch, idx=i)\n",
    "            img_dis_map_pred_left, pred_left_min_dis, pred_left_max_dis = calculate_distance2D_list(single_pred[:,:, 0], single_l_center,pred=\"Pred\", save=save, epoch=epoch, batch=batch, idx=i)\n",
    "            img_dis_map_pred_right, pred_right_min_dis, pred_right_max_dis = calculate_distance2D_list(single_pred[:,:, 1], single_r_center,pred=\"Pred\", save=save, epoch=epoch, batch=batch, idx=i)\n",
    "            \n",
    "            blue_channel = np.zeros((single_target.shape[0], single_target.shape[1],1))\n",
    "            print(\"blue channel.shape:\", blue_channel.shape)\n",
    "            single_RGB_target = np.concatenate((single_target,blue_channel), axis=-1)\n",
    "\n",
    "\n",
    "            fig = plt.figure(figsize=(16, 16))\n",
    "            gs = gridspec.GridSpec(nrows=4, ncols=4, height_ratios=[2, 2, 2, 2], width_ratios=[1, 1, 1, 1], left=0.15, bottom=0.15, right=0.85, top=0.85,\n",
    "            wspace=0.0, hspace=0.5)\n",
    "            ax0 = fig.add_subplot(gs[0, 0:3])  # for the input\n",
    "            ax1 = fig.add_subplot(gs[0, 3:])  # for RGB labels\n",
    "            ax2 = fig.add_subplot(gs[1, 0])  # for left label\n",
    "            ax6 = fig.add_subplot(gs[1, 1])  # for left distance map\n",
    "            ax3 = fig.add_subplot(gs[1, 2])  # for right label\n",
    "            ax7 = fig.add_subplot(gs[1, 3])  # for rgith distance map\n",
    "            \n",
    "            ax4 = fig.add_subplot(gs[2, 0])  # for predict left labbel\n",
    "            ax9 = fig.add_subplot(gs[2, 1])  # for predict left dismap\n",
    "            ax5 = fig.add_subplot(gs[2, 2])  # for predicted right label\n",
    "            ax10 = fig.add_subplot(gs[2, 3])  # for predict right dismap\n",
    "            \n",
    "            ax8 = fig.add_subplot(gs[3:, :])  # for predicted rgb label\n",
    "\n",
    "\n",
    "            print(\"single_input.shape\", single_input.shape)\n",
    "            print(\"single_target.shape\", single_target.shape)\n",
    "\n",
    "            ax0.imshow(single_input)\n",
    "            ax0.set_title('single input range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_input), np.max(single_input)))\n",
    "\n",
    "            ax1.imshow(single_RGB_target)\n",
    "            ax1.set_title('single_RGB_target range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_RGB_target), np.max(single_RGB_target)))\n",
    "            \n",
    "            \n",
    "            print(tar_left_max_dis)\n",
    "           # targ cricle left\n",
    "            circle_tar_left =  plt.Circle((single_l_center[0]*224, single_l_center[1]*224), tar_left_max_dis.numpy()*224, fill=False, color=\"r\")\n",
    "            ax2.add_artist(circle_tar_left)\n",
    "            ax2.imshow(single_target[:,:, 0])\n",
    "            ax2.scatter(single_l_center[0]*224, single_l_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax2.set_title('label left range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_target[:,:, 0]), np.max(single_target[:,:, 0])))\n",
    "            \n",
    "            \n",
    "            # targ cricle right\n",
    "            circle_tar_right =  plt.Circle((single_r_center[0]*224, single_r_center[1]*224), tar_right_max_dis.numpy()*224, fill=False, color=\"r\")\n",
    "            ax3.add_artist(circle_tar_right)\n",
    "            ax3.imshow(single_target[:,:, 1])\n",
    "            ax3.scatter(single_r_center[0]*224, single_r_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax3.set_title('label rights range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_target[:,:, 1]), np.max(single_target[:,:, 1])))\n",
    "            \n",
    "            # pred cricle left\n",
    "            circle_pred_left =  plt.Circle((single_l_center[0]*224, single_l_center[1]*224), pred_left_max_dis.numpy()*224, fill=False, color=\"r\")\n",
    "            ax4.add_artist(circle_pred_left)\n",
    "            ax4.imshow(single_pred[:,:, 0])\n",
    "            ax4.scatter(single_l_center[0]*224, single_l_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax4.set_title('pred left range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_pred[:,:, 0]), np.max(single_pred[:,:, 0])))\n",
    "            \n",
    "            # pred cricle right\n",
    "            circle_pred_right =  plt.Circle((single_r_center[0]*224, single_r_center[1]*224), pred_right_max_dis.numpy()*224, fill=False, color=\"r\")\n",
    "            ax5.add_artist(circle_pred_right)\n",
    "            ax5.imshow(single_pred[:,:, 1])\n",
    "            ax5.scatter(single_r_center[0]*224, single_r_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax5.set_title('pred right range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_pred[:,:, 1]), np.max(single_pred[:,:, 1])))\n",
    "            \n",
    "            ax6.imshow(img_dis_map_left,interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#             ax6.colorbar() \n",
    "#             ax6.scatter(single_l_center[0]*224, single_l_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax6.set_title('tar left dis.range:\\n[{:.4f}, {:.4f}]'.format(tar_left_min_dis, tar_left_max_dis))\n",
    "\n",
    "            ax7.imshow(img_dis_map_right,interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#             ax7.colorbar() \n",
    "#             ax7.scatter(single_r_center[0]*224, single_r_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax7.set_title('tar right dis.range:\\n[{:.4f}, {:.4f}]'.format(tar_right_min_dis, tar_right_max_dis))\n",
    "            \n",
    "            ax9.imshow(img_dis_map_pred_left,interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#             ax6.colorbar() \n",
    "#             ax6.scatter(single_l_center[0]*224, single_l_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax9.set_title('pred left dis.range:\\n[{:.4f}, {:.4f}]'.format(pred_left_min_dis, pred_left_max_dis))\n",
    "\n",
    "            ax10.imshow(img_dis_map_pred_right,interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#             ax7.colorbar() \n",
    "#             ax7.scatter(single_r_center[0]*224, single_r_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax10.set_title('pred right dis.range:\\n[{:.4f}, {:.4f}]'.format(pred_right_min_dis, pred_right_max_dis))\n",
    "            \n",
    "        \n",
    "        \n",
    "            # prdeicted_RGB\n",
    "            predicted_RGB_target = np.concatenate((single_pred,blue_channel), axis=-1)\n",
    "            ax8.imshow(predicted_RGB_target)\n",
    "            ax8.set_title('pred RGB range:\\n[{:.4f}, {:.4f}]\\n dice:{} \\n C_iou_loss:{}'.format(np.min(predicted_RGB_target), np.max(predicted_RGB_target), 1-d_loss, c_iou_loss))\n",
    "\n",
    "            plt.tight_layout()\n",
    "           \n",
    "            if train:\n",
    "                fig.savefig(train_save_figure_path + \"/Train_image_at_epoch_{:04d}_batch_{}_idx_{}.png\".format(epoch, batch, i),  dpi=300)  \n",
    "            else:\n",
    "                fig.savefig(test_EpochValidation_save_path + \"/Test_image_at_epoch_{:04d}_batch_{}_idx_{}.png\".format(epoch, batch, i),  dpi=300) \n",
    "            plt.show()\n",
    "  \n",
    "        else:\n",
    "            blue_channel = np.zeros((single_target.shape[0], single_target.shape[1],1))\n",
    "            print(\"blue channel.shape:\", blue_channel.shape)\n",
    "            single_RGB_target = np.concatenate((single_target,blue_channel), axis=-1)\n",
    "\n",
    "\n",
    "            fig = plt.figure(figsize=(18, 12))\n",
    "            gs = gridspec.GridSpec(nrows=4, ncols=2, height_ratios=[2, 1, 1, 2], width_ratios=[1, 1], left=0.3, bottom=0.1, right=0.7, top=0.95,\n",
    "            wspace=0.0, hspace=0.5)\n",
    "            ax0 = fig.add_subplot(gs[0, 0])  # for the input\n",
    "            ax1 = fig.add_subplot(gs[0, 1])  # for RGB labels\n",
    "            ax2 = fig.add_subplot(gs[1, 0])  # for left label\n",
    "            ax3 = fig.add_subplot(gs[1, 1])  # for right label\n",
    "            ax4 = fig.add_subplot(gs[2, 0])  # for predict left labbel\n",
    "            ax5 = fig.add_subplot(gs[2, 1])  # for predicted right label\n",
    "            ax6 = fig.add_subplot(gs[3:, :])  # for predicted rgb label\n",
    "\n",
    "\n",
    "            print(\"single_input.shape\", single_input.shape)\n",
    "            print(\"single_target.shape\", single_target.shape)\n",
    "\n",
    "            ax0.imshow(single_input)\n",
    "            ax0.set_title('single input range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_input), np.max(single_input)))\n",
    "\n",
    "            ax1.imshow(single_RGB_target)\n",
    "            ax1.set_title('single_RGB_target range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_RGB_target), np.max(single_RGB_target)))\n",
    "\n",
    "            ax2.imshow(single_target[:,:, 0])\n",
    "            ax2.scatter(single_l_center[0]*224, single_l_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax2.set_title('label left range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_target[:,:, 0]), np.max(single_target[:,:, 0])))\n",
    "\n",
    "            ax3.imshow(single_target[:,:, 1])\n",
    "            ax3.scatter(single_r_center[0]*224, single_r_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax3.set_title('label rights range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_target[:,:, 1]), np.max(single_target[:,:, 1])))\n",
    "\n",
    "            ax4.imshow(single_pred[:,:, 0])\n",
    "            ax4.scatter(single_l_center[0]*224, single_l_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax4.set_title('pred left range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_pred[:,:, 0]), np.max(single_pred[:,:, 0])))\n",
    "\n",
    "            ax5.imshow(single_pred[:,:, 1])\n",
    "            ax5.scatter(single_r_center[0]*224, single_r_center[1]*224, s=160, c='C0', marker='+')\n",
    "            ax5.set_title('pred right range:\\n[{:.4f}, {:.4f}]'.format(np.min(single_pred[:,:, 1]), np.max(single_pred[:,:, 1])))\n",
    "\n",
    "            # prdeicted_RGB\n",
    "            predicted_RGB_target = np.concatenate((single_pred,blue_channel), axis=-1)\n",
    "            ax6.imshow(predicted_RGB_target)\n",
    "            ax6.set_title('pred RGB range:\\n[{:.4f}, {:.4f}]\\n dice:{} \\n C_iou_loss:{}'.format(np.min(predicted_RGB_target), np.max(predicted_RGB_target), 1-d_loss, c_iou_loss))\n",
    "\n",
    "            plt.tight_layout()\n",
    "   \n",
    "            plt.show()\n",
    "#     if save==True :\n",
    "#         if Train_or_not:\n",
    "#             fig.savefig(train_save_figure_path + \"/Train_image_at_epoch_{:04d}_batch_{}.png\".format(epoch,batch_idx))\n",
    "#         else:\n",
    "#             if Epoch_val:\n",
    "#                 fig.savefig(test_EpochValidation_save_path + \"/Test_image_at_epoch_{:04d}_batch_{}_idx.png\".format(epoch,batch_idx))\n",
    "#             else:\n",
    "#                 fig.savefig(test_save_figure_path + \"/Test_image_at_epoch_{:04d}_batch_{}.png\".format(epoch,batch_idx))\n",
    "     \n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "# def test_predict_all_images(model, batch_input, batch_seg_target, epoch): \n",
    "#     for i in range(batch_seg_target.shape[0]):\n",
    "#         check_mean_feature_images(model, batch_input, batch_seg_target, epoch, i, save =True, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for final_element in final_train_dataset.take(1):\n",
    "#     tr_input =  final_element[0][0]\n",
    "#     tr_label =  final_element[0][1]\n",
    "#     tr_query =  final_element[1]\n",
    "#     print(\"tr_input.shape:\", tr_input.shape)\n",
    "#     # check the feature extractor\n",
    "#     input_extracted_features = down_stack.predict(tr_input)\n",
    "#     query_extracted_features = down_stack.predict(tr_query)\n",
    "    \n",
    "# #     check_predict_images(One_shot_MobileNetV2UNet, [tr_input, tr_query], tr_label, 1, 1, save=False, Train_or_not=True, Epoch_val =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr_elements in train_dataset.take(1):\n",
    "    print(len(tr_elements))\n",
    "    print(tr_elements[0].shape)\n",
    "    print(tr_elements[1].shape)\n",
    "    print(tr_elements[2])\n",
    "    print(tr_elements[3])\n",
    "    print(tr_elements[4])\n",
    "    check_predictions(One_shot_MobileNetV2UNet,tr_elements, 1, 1, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_total_loss_tb(writer, avg_losses, name, epoch):\n",
    "    \"\"\"\n",
    "     avg_losses = [total_loss, seg_loss, cls_loss]\n",
    "    \"\"\"\n",
    "    with writer.as_default():\n",
    "        print(\"writing \"+name +\" logs to tensorboard...\")                                                       \n",
    "        # write scalars to the tensorboard after each train step\n",
    "        tf.summary.scalar(name, avg_losses.result(), step=epoch)\n",
    "        \n",
    "def write_single_scalar_tb(writer, avg_losses, name, epoch):\n",
    "    \"\"\"\n",
    "     avg_losses = [total_loss, seg_loss, cls_loss]\n",
    "    \"\"\"\n",
    "    with writer.as_default():\n",
    "        print(\"writing \"+ name +\" logs to tensorboard...s\")                                                       \n",
    "        # write scalars to the tensorboard after each train step\n",
    "        tf.summary.scalar(name, avg_losses, step=epoch)\n",
    "        \n",
    "def train_display_save_at(model, tr_elements,   step, epoch, freq_step =200, save=True, Train_or_not=True):\n",
    "    if step % freq_step ==0:\n",
    "        print(\"train image checking----------------------------------------------------------------------------------->\")\n",
    "        check_predictions(model,tr_elements, epoch, step, save=True, train = Train_or_not )\n",
    "#         check_predict_images(model, batch_inputs, batch_labels,  step, epoch, pred, save=save, Train_or_not=Train_or_not, Epoch_val =False)\n",
    "        \n",
    "def test_at_each_epoch(val_dataset, model, step, epoch, temp_dice, global_count_test, save=True, training=False):\n",
    "    # initialize \n",
    "#     epoch_val_flag = True\n",
    "    # initialize for evaluating average metric\n",
    "    test_total_loss_mean = tf.keras.metrics.Mean()\n",
    "    test_total_dice_mean = tf.keras.metrics.Mean()\n",
    "    test_total_Dice_loss_mean = tf.keras.metrics.Mean()\n",
    "    test_total_C_iou_loss_mean = tf.keras.metrics.Mean()\n",
    "#     manual_avg_dice = []\n",
    "    count = 0\n",
    "    for te_final_element in val_dataset:\n",
    "#         te_inputs =  te_final_element[0]\n",
    "#         te_labels =  te_final_element[1]\n",
    "#         te_paths =  te_final_element[2]\n",
    "        te_inputs =  te_final_element[0]\n",
    "        te_labels =  te_final_element[1]\n",
    "        te_paths =  te_final_element[2]\n",
    "        te_l_centers =  te_final_element[3]\n",
    "        te_r_centers = te_final_element[4]\n",
    "            \n",
    "  \n",
    "#         te_l_centers, te_r_centers = return_left_right_cententers(te_final_element[1], te_final_element[2])\n",
    "    \n",
    "    \n",
    "        # one train step loss calculation and optimization  model2, inputs, cls_target, training\n",
    "        te_total_loss, te_seg_pred, te_dice, te_Dice_loss, te_c_iou_loss = new_test_step(model, te_inputs, te_labels, te_l_centers, te_r_centers,  training=False)\n",
    "        test_total_loss_mean(te_total_loss)\n",
    "        test_total_dice_mean(te_dice)\n",
    "        test_total_C_iou_loss_mean(te_c_iou_loss)\n",
    "        test_total_Dice_loss_mean(te_Dice_loss)\n",
    "\n",
    "        count+=1\n",
    "        print('[Test]Epoch: {} batch:{} \\n  total_loss: {} , dice_loss: {}, c_iou_loss: {}'.\n",
    "              format(epoch, count, test_total_loss_mean.result(), test_total_Dice_loss_mean.result(), test_total_C_iou_loss_mean.result()))\n",
    "        \n",
    "        if global_count_test %25 ==0:\n",
    "            display.clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "        check_predictions(model, te_final_element, epoch, count, save=True, train = False )\n",
    "    \n",
    "    \n",
    "#     # write logs to tensorboard:    avg_losses = [total_loss, seg_loss, cls_loss]\n",
    "#     # write test losses to the tensorboard\n",
    "    print(\"writing test logs to tensorboard...\") \n",
    "    write_single_total_loss_tb(val_summary_writer, test_total_loss_mean, \"total_loss_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(val_summary_writer, test_total_dice_mean, \"Avg_dice_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(val_summary_writer, test_total_Dice_loss_mean, \"Dice_loss_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(val_summary_writer, test_total_C_iou_loss_mean, \"C_iou_loss_per_epoch\", epoch)\n",
    "    \n",
    "    print(\"temp_dice:\", temp_dice.numpy())\n",
    "    if test_total_dice_mean.result() > temp_dice:\n",
    "        save_path =  new_manager.save(checkpoint_number=epoch) # save the checkpoint and return the save path\n",
    "        print(\"Saved checkpoint for epoch {}-  step {}: {}\".format(epoch, step, save_path))\n",
    "        temp_dice.assign(test_total_dice_mean.result())\n",
    "\n",
    "\n",
    "# defin one epoch training for different dataset\n",
    "def train_one_epoch(train_dataset, model, optimizer, step, epoch):\n",
    "    #  initializations at each epoch \n",
    "    train_total_loss_mean = tf.keras.metrics.Mean()\n",
    "    train_total_dice_mean = tf.keras.metrics.Mean()\n",
    "    train_total_Dice_loss_mean = tf.keras.metrics.Mean()\n",
    "    train_total_C_iou_loss_mean = tf.keras.metrics.Mean()\n",
    "#     train_total_ed_loss_mean = tf.keras.metrics.Mean()\n",
    "    \n",
    "    for tr_final_element in train_dataset:\n",
    "        tr_inputs =  tr_final_element[0]\n",
    "        tr_labels =  tr_final_element[1]\n",
    "        tr_paths =  tr_final_element[2]\n",
    "        tr_l_centers =  tr_final_element[3]\n",
    "        tr_r_centers = tr_final_element[4]\n",
    "  \n",
    "#         tr_l_centers, tr_r_centers = return_left_right_cententers(tr_final_element[1], tr_final_element[2])\n",
    " \n",
    "        # one train step loss calculation and optimization model, optimizer, inputs, seg_target, centers_left, centers_right\n",
    "        tr_total_loss, tr_seg_pred, tr_dice, tr_Dice_loss, tr_c_iou_loss = new_train_step(model, optimizer, tr_inputs, tr_labels, tr_l_centers, tr_r_centers,  training=True)\n",
    "        train_total_loss_mean(tr_total_loss)\n",
    "        train_total_dice_mean(tr_dice)\n",
    "        train_total_C_iou_loss_mean(tr_c_iou_loss)\n",
    "        train_total_Dice_loss_mean(tr_Dice_loss)\n",
    "\n",
    "        \n",
    "        if optimizer.iterations.numpy() % 10 == 0: \n",
    "#             write_single_total_loss_tb(train_summary_writer, train_total_loss_mean, \"train_total_loss_per_batch\", optimizer.iterations.numpy())\n",
    "            write_single_scalar_tb(train_summary_writer,  optimizer._decayed_lr(var_dtype=tf.float32), \"Optimizer Lr\", optimizer.iterations.numpy())\n",
    "#             write_single_scalar_tb(train_summary_writer,  train_total_dice_mean.result(), \"tr_Dice\", optimizer.iterations.numpy())\n",
    "#             write_single_scalar_tb(train_summary_writer,  train_total_ed_loss_mean.result(), \"tr_ed_loss\", optimizer.iterations.numpy())\n",
    "        print('Epoch: {} batch:{} \\n Train total_loss: {}, Train dice_loss: {}, Train C_IoU_loss: {}'.\n",
    "              format(epoch, int(step), train_total_loss_mean.result(), train_total_Dice_loss_mean.result(), train_total_C_iou_loss_mean.result()))\n",
    "        \n",
    "        #  the saved figure is the prediction with test model with input training dataset\n",
    "        train_display_save_at(model, tr_final_element,  int(step), epoch, freq_step =20, save=True, Train_or_not=True) \n",
    "\n",
    "        if step % 25 ==0:\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "        step.assign_add(1)\n",
    "        \n",
    "    \n",
    "     # write train epoch average loss to the tensorboard\n",
    "    print(\"writing train logs to tensorboard...\") \n",
    "    write_single_total_loss_tb(train_summary_writer, train_total_loss_mean, \"total_loss_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(train_summary_writer, train_total_dice_mean, \"Avg_dice_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(train_summary_writer, train_total_Dice_loss_mean, \"Dice_loss_per_epoch\", epoch)\n",
    "    write_single_total_loss_tb(train_summary_writer, train_total_C_iou_loss_mean, \"C_iou_loss_per_epoch\", epoch)\n",
    "#     write_single_total_loss_tb(train_summary_writer, train_total_ed_loss_mean, \"Avg_ed_loss_per_epoch\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take_new_train_batches =  3035\n",
    "def train_process(train_dataset, val_dataset, model, optimizer, step, start_epoch,global_test_step, global_dice_temp, total_epochs):\n",
    "    # some initial parameters\n",
    "    # test average_loss = for saving the test results\n",
    "#     test_avg_tmp_dice =1\n",
    "#     global_count_test = 1\n",
    "    for epoch in range(int(start_epoch), total_epochs+1):\n",
    "      \n",
    "    \n",
    "        # train one epoch， including loss calculation and optimization\n",
    "        train_one_epoch(train_dataset, model, optimizer, step, epoch)\n",
    "        \n",
    "        # one training epoch ended start to evaluate the performance through entire test dataset\n",
    "        test_at_each_epoch(val_dataset, model, int(step), epoch, temp_dice=global_dice_temp, global_count_test=global_test_step ,save=True, training = False)\n",
    "      \n",
    "      \n",
    "        # when epoch fisnihed add epoch counter and reset the batch step \n",
    "        start_epoch.assign_add(1)     \n",
    "        step.assign(1)\n",
    "        \n",
    "        \n",
    "    # when training finihsed\n",
    "    print(\"training finished\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    init_lr = 5e-4\n",
    "    learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "      initial_learning_rate=init_lr,\n",
    "      decay_steps=10000,\n",
    "      end_learning_rate=0.00005)\n",
    "#     learning_rate_fn = 1e-3\n",
    "    new_optimizer =  tf.keras.optimizers.Adam(learning_rate_fn)\n",
    "    # build_new check point manager\n",
    "    new_ckpt_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    if not os.path.exists(new_ckpt_prefix):\n",
    "        os.makedirs(new_ckpt_prefix)\n",
    "    #  contents of states to be saved as attributes on the checkpoint object\n",
    "    new_ckpt_ob = tf.train.Checkpoint(step= tf.Variable(1),\n",
    "                                      epoch=  tf.Variable(1),\n",
    "                                      global_test_step =  tf.Variable(1),\n",
    "                                      global_dice_temp =  tf.Variable(0.0),\n",
    "                                        optimizer=new_optimizer,\n",
    "                                         model =  One_shot_MobileNetV2UNet\n",
    "                                     )\n",
    "    # define checkpoint manager\n",
    "    new_manager =  tf.train.CheckpointManager(new_ckpt_ob, new_ckpt_prefix, max_to_keep=1)\n",
    "\n",
    "    # check the whether there is a checkpoint in the checkpoint folder, if it is restore from it\n",
    "    if new_manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(new_manager.latest_checkpoint))\n",
    "        new_ckpt_ob.restore(new_manager.latest_checkpoint)\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    # reset checkcpoint.step for each epoch\n",
    "    step =  new_ckpt_ob.step\n",
    "    ckpt_epoch =  new_ckpt_ob.epoch  \n",
    "    optimizer = new_ckpt_ob.optimizer\n",
    "    model = new_ckpt_ob.model\n",
    "    epochs = 1000\n",
    "    global_test_step = new_ckpt_ob.global_test_step\n",
    "    global_dice_temp = new_ckpt_ob.global_dice_temp\n",
    "    # start train_process\n",
    "    train_process(train_dataset, test_dataset, model, optimizer, step, ckpt_epoch, global_test_step, global_dice_temp, total_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(range(224*224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
